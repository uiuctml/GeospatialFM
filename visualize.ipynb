{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "\n",
    "from GeospatialFM.data import get_datasets\n",
    "from GeospatialFM.models import *\n",
    "# from utils import load_config\n",
    "from torchgeo.samplers import RandomGeoSampler\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from GeospatialFM.utils import setup, get_eval_fn\n",
    "from GeospatialFM.data import *\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.data import ConcatDataset\n",
    "import segmentation_models_pytorch as smp\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'exp_name': None,\n",
    "        'config_file': 'GeospatialFM/configs/bigearthnet/bn_rn50_dino.yaml',\n",
    "        'opts': None, \n",
    "        'save_config': False}\n",
    "args = argparse.Namespace(**args)\n",
    "args.debug = True\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg, _ = setup(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg['DATASET']['kwargs'] = dict(bands='all', pad_s2=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = get_datasets(cfg['DATASET'])\n",
    "# training_args = TrainingArguments(**cfg['TRAINER'])\n",
    "# model = construct_model(cfg['MODEL'])\n",
    "# compute_metrics = get_eval_fn(cfg['DATASET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_ds[0]['image']\n",
    "# visulize each channel of the image\n",
    "fig, axes = plt.subplots(2, 6, figsize=(12, 4))\n",
    "channel_name = ['VV', 'VH', 'B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12']\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.axis('off')\n",
    "    ax.imshow(sample[i])\n",
    "    ax.set_title(channel_name[i])\n",
    "plt.tight_layout()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_ds[0]['image']\n",
    "# visulize each channel of the image\n",
    "# fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "# channel_name = ['VV', 'VH', 'B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12']\n",
    "# masked = np.random.choice(np.arange(12), 4, replace=False)\n",
    "plt.imshow(sample[0])\n",
    "    # ax.set_title(channel_name[i])\n",
    "# plt.tight_layout()  \n",
    "# fig.subplots_adjust(hspace=0, wspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 4))\n",
    "plt.axis('off')\n",
    "img = sample[[5, 4, 3]].permute(1, 2, 0)\n",
    "# normalize the image\n",
    "img = img / img.max()\n",
    "plt.imshow(img)\n",
    "plt.title('RGB')\n",
    "plt.tight_layout()  \n",
    "# save as pdf\n",
    "plt.savefig('rgb.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = gridspec.GridSpec(2, 9)\n",
    "fig = plt.figure(figsize=(18, 4))\n",
    "\n",
    "# Plotting the large image which occupies 4 grid spaces\n",
    "ax1 = fig.add_subplot(gs[0:2, 0:2])\n",
    "img = sample[[5, 4, 3]].permute(1, 2, 0)\n",
    "img = (img-img.min())/(img.max()-img.min())\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('RGB')\n",
    "ax1.axis('off')\n",
    "\n",
    "# Plotting the other images in the remaining spaces\n",
    "for x in range(2):\n",
    "    for y in range(2, 9):\n",
    "        i = y - 2 if x == 0 else y + 5    \n",
    "        ax = fig.add_subplot(gs[x, y])\n",
    "        ax.imshow(sample[i])\n",
    "        ax.set_title(channel_name[i])\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig('channels.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Number of parameters: {num_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model.base_model's weights to segmentation model encoder\n",
    "seg_model.encoder.load_state_dict(model.base_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_model.encoder.conv1.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds[0]['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds[0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = model(train_ds[0]['image'].unsqueeze(0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ConcatDataset([train_ds, val_ds])\n",
    "train_dl = DataLoader(train_ds, batch_size=512, shuffle=True, num_workers=8)\n",
    "test_dl = DataLoader(test_ds, batch_size=512, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                   # training arguments, defined above\n",
    "    train_dataset=train_ds,    # training dataset\n",
    "    eval_dataset=test_ds,      # evaluation dataset\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(model, dataloader, device):\n",
    "    x_all = []\n",
    "    y_all = []\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "        images = batch[\"image\"].to(device)\n",
    "        labels = batch[\"label\"].numpy()\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            features = model(images).cpu().numpy()\n",
    "        \n",
    "        x_all.append(features)\n",
    "        y_all.append(labels)\n",
    "\n",
    "    x_all = np.concatenate(x_all, axis=0)\n",
    "    y_all = np.concatenate(y_all, axis=0)\n",
    "\n",
    "    return x_all, y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all, y_all = extract_features(model.base_model, train_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = extract_features(model.base_model, test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = LogisticRegression(C=50.0, max_iter=1000)\n",
    "linear_model.fit(x_all, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = cfg['MODEL']\n",
    "model_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = construct_model(model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tgm.get_weight(model_cfg['pretrained_ckpt'])\n",
    "encoder = tgm.get_model(model_cfg['architecture'], weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.head.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the last layer of the encoder\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timm.list_models('*dino*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "224/14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
