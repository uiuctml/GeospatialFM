{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haozhesi/anaconda3/envs/sat/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "from GeospatialFM.data import get_datasets\n",
    "from GeospatialFM.models import *\n",
    "\n",
    "from GeospatialFM.utils import *\n",
    "from GeospatialFM.data import *\n",
    "from GeospatialFM.models import *\n",
    "from GeospatialFM.loss import *\n",
    "\n",
    "from tqdm import trange\n",
    "import random\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_name = 'mae_cm_reconall_scratch_allTrain'\n",
    "# exp_name = 'mae_unidecoder_scratch_allTrain_norwl'\n",
    "n_spectral_blocks = 1\n",
    "n_spatial_spectral_blocks = 2\n",
    "n_spatial_blocks = 9\n",
    "exp_name = f\"mm_vit_{n_spectral_blocks}-{n_spatial_spectral_blocks}-{n_spatial_blocks}_d4_new\"\n",
    "# exp_name = \"mae_base_cvit\"\n",
    "device = torch.device('cuda:5')\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(exp_name='mm_vit_1-2-9_d4_new', config_file='GeospatialFM/configs/finetune_mm_cvit.yaml', opts=None, save_config=False, device='cuda:5', finetune_modal='multi_modal', debug=True, finetune=True, distributed=False, world_size=1, rank=0, local_rank=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = {'exp_name': exp_name,\n",
    "        'config_file': 'GeospatialFM/configs/finetune_mm_cvit.yaml',\n",
    "        'opts': None, \n",
    "        'save_config': False,\n",
    "        'device': 5,\n",
    "        'finetune_modal': 'multi_modal'}\n",
    "args = argparse.Namespace(**args)\n",
    "args.debug = True\n",
    "args.finetune = True\n",
    "device = init_distributed_device(args)\n",
    "cfg, _ = setup(args)\n",
    "cfg.MODEL.MULTI_MODAL.kwargs.spectral_blocks = n_spectral_blocks\n",
    "cfg.MODEL.MULTI_MODAL.kwargs.sptial_spectral_blocks = n_spatial_spectral_blocks\n",
    "cfg.MODEL.load_pretrained_from = 'dir'\n",
    "cfg.MODEL.MULTI_MODAL.kwargs.low_rank_feature = True\n",
    "cfg.MODEL.MULTI_MODAL.kwargs.dim_ratio=0.25\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_train_epochs': 20, 'per_device_train_batch_size': 128, 'per_device_eval_batch_size': 128, 'gradient_accumulation_steps': 4, 'learning_rate': 0.001, 'weight_decay': 0.05, 'dataloader_num_workers': 8, 'dataloader_pin_memory': True, 'dataloader_drop_last': False, 'optim': 'adamw_torch', 'lr_scheduler_type': 'cosine', 'warmup_epochs': 4, 'scheduler_kwargs': None, 'save_strategy': 'epoch', 'evaluation_strategy': 'epoch', 'load_best_model_at_end': True, 'metric_for_best_model': 'accuracy', 'greater_is_better': True, 'logging_dir': './results/logs/BigEarthNet_mm_lr_vit_base_patch16_224_mm_vit_1-2-9_d4_new', 'logging_strategy': 'steps', 'logging_steps': 50, 'report_to': None, 'output_dir': './results/models/BigEarthNet_mm_lr_vit_base_patch16_224_mm_vit_1-2-9_d4_new', 'save_total_limit': 5, 'overwrite_output_dir': False, 'seed': 0, 'fp16': True, 'push_to_hub': False, 'save_frequency': 10, 'ckpt_dir': './results/models/mm_lr_vit_base_patch16_224_mm_vit_1-2-9_d4_new'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.TRAINER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained weights from ./results/models/mm_lr_vit_base_patch16_224_mm_vit_1-2-9_d4_new/final_model.pth...\n",
      "The model hanles modality by multi_modal...\n",
      "Targeting multi_modal encoder...\n",
      "Constructing mm_lr_vit_base_patch16_224 encoder...\n",
      "Using Multi-Modal LowRank ViT...\n",
      "Spectral Blocks: 1\tSptial-Spectral Blocks: 2\tSpatial Blocks: 9\n",
      "Using NCD Pooling\n",
      "Using NCD Pooling\n",
      "Loading pretrained weights for multi_modal encoder...\n",
      "Number of parameters for Encoder: 93020064\n",
      "Constructing linear head...\n"
     ]
    }
   ],
   "source": [
    "model = construct_downstream_models(cfg, target_modal=args.finetune_modal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiModalLowRankViTEncoder(\n",
       "  (blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (1-2): 2 x LowRankBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): LowRankAttention(\n",
       "        (qkv_c): Linear(in_features=768, out_features=144, bias=True)\n",
       "        (qkv_s): Linear(in_features=768, out_features=576, bias=True)\n",
       "        (qc_norm): Identity()\n",
       "        (kc_norm): Identity()\n",
       "        (qs_norm): Identity()\n",
       "        (ks_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (3-11): 9 x Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (head): Identity()\n",
       "  (radar_patch_embed): PatchEmbedPerChannel(\n",
       "    (proj): Sequential(\n",
       "      (0): Conv3d(1, 1536, kernel_size=(1, 16, 16), stride=(1, 16, 16))\n",
       "      (1): Conv3d(1536, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (channel_embed): Embedding(2, 768)\n",
       "  )\n",
       "  (channel_pool): AdaptiveMaxPool1d(output_size=1)\n",
       "  (radar_spectral_blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Channels: 12\n",
      "Training Dataset: BigEarthNet\n",
      "Train Set: 26969\t Val Set: 12372\t Test Set: 125866\n"
     ]
    }
   ],
   "source": [
    "data_idx = 41982\n",
    "data = get_data(cfg)\n",
    "sample = data['test'].dataloader.dataset[data_idx]\n",
    "for key in sample:\n",
    "    sample[key] = sample[key].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.0272, -0.9353, -0.8286,  ..., -0.6709, -0.7892, -1.0139],\n",
       "          [-1.0452, -0.9646, -0.8134,  ..., -0.2625, -0.3484, -0.5600],\n",
       "          [-0.9656, -0.8879, -0.7183,  ..., -0.0288, -0.0823, -0.2611],\n",
       "          ...,\n",
       "          [-1.4852, -1.1559, -0.8923,  ..., -1.0711, -0.9008, -0.6822],\n",
       "          [-1.5152, -1.3264, -1.1180,  ..., -1.1395, -0.9546, -0.7435],\n",
       "          [-1.4873, -1.5378, -1.4389,  ..., -1.2485, -1.0531, -0.8549]],\n",
       "\n",
       "         [[ 1.5767,  1.5288,  1.5272,  ...,  1.7101,  1.6934,  1.6822],\n",
       "          [ 1.7202,  1.7696,  1.8023,  ...,  1.6281,  1.5838,  1.5830],\n",
       "          [ 1.7928,  1.8721,  1.9104,  ...,  1.5611,  1.5331,  1.5312],\n",
       "          ...,\n",
       "          [ 1.8053,  2.0721,  2.2620,  ...,  1.8298,  1.9648,  2.0610],\n",
       "          [ 1.8167,  2.0844,  2.2758,  ...,  1.8356,  1.9368,  1.9940],\n",
       "          [ 1.7791,  2.0030,  2.1698,  ...,  1.7676,  1.8097,  1.8005]]]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['radar']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
