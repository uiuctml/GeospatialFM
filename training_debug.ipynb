{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haozhesi/anaconda3/envs/sat/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "from GeospatialFM.data import get_datasets\n",
    "from GeospatialFM.models import *\n",
    "\n",
    "from GeospatialFM.utils import *\n",
    "from GeospatialFM.data import *\n",
    "from GeospatialFM.models import *\n",
    "from GeospatialFM.loss import *\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'debug'\n",
    "args = [\"--exp_name\", exp_name, \"--config_file\", \"GeospatialFM/configs/mae_cm.yaml\", \"--device_ids\", \"1\", \"7\", \"--debug\"]\n",
    "args = get_args_parser().parse_args(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.debug:\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "cfg, _ = setup(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scale': 1.0, 'recon_all': True, 'cross_modal_recon': False, 'channel_reweight': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.LOSS['MAE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = dict(\n",
    "    device_ids = args.device_ids,\n",
    "    device = 'cpu',\n",
    "    precision = None,\n",
    "    accum_freq = cfg['TRAINER']['gradient_accumulation_steps'],\n",
    "    grad_clip_norm = None,\n",
    "    log_every_n_steps = cfg['TRAINER']['logging_steps'],\n",
    "    wandb = cfg['TRAINER']['report_to'] == 'wandb',\n",
    "    batch_size = cfg['TRAINER']['per_device_train_batch_size'],\n",
    "    val_frequency = 1,\n",
    "    epochs = cfg['TRAINER']['num_train_epochs'],\n",
    "    save_logs = True,\n",
    "    checkpoint_path = cfg['TRAINER']['logging_dir'],\n",
    "    mask_ratio = cfg['MODEL']['mask_ratio']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = argparse.Namespace(**training_args)\n",
    "training_args.device = f'cuda:{training_args.device_ids[0]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = construct_mae(cfg.MODEL)\n",
    "model = model.to(training_args.device)\n",
    "if len(training_args.device) > 1:\n",
    "    model = torch.nn.DataParallel(model, device_ids=training_args.device_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps = data['train'].dataloader.num_batches * cfg['TRAINER']['num_train_epochs']\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=cfg['TRAINER']['learning_rate'], weight_decay=cfg['TRAINER']['weight_decay'])\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=steps, eta_min=1e-7)\n",
    "# loss = get_loss_list(cfg.LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train one iter\n",
    "# device = torch.device(training_args.device)\n",
    "# autocast = get_autocast(training_args.precision)\n",
    "# model.train()\n",
    "\n",
    "# dataloader = data['train'].dataloader\n",
    "# num_batches_per_epoch = dataloader.num_batches // training_args.accum_freq\n",
    "# sample_digits = math.ceil(math.log(dataloader.num_samples + 1, 10))\n",
    "\n",
    "# batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, radar, label = batch['image'], batch['radar'], batch['label']\n",
    "# images = images.to(device=device, non_blocking=True)\n",
    "# radar = radar.to(device=device, non_blocking=True)\n",
    "# label = label.to(device=device, non_blocking=True)  \n",
    "\n",
    "# optimizer.zero_grad()\n",
    "\n",
    "# with autocast():\n",
    "#     model_out = model(images, radar, mask_ratio=0)\n",
    "#     model_out['labels'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with autocast():    \n",
    "#     if isinstance(loss, list):\n",
    "#         losses = {}\n",
    "#         for l in loss:\n",
    "#             losses.update(l(**model_out, output_dict=True))\n",
    "#     else:\n",
    "#         losses = loss(**model_out, output_dict=True)\n",
    "\n",
    "#     total_loss = sum(losses.values())\n",
    "#     losses[\"loss\"] = total_loss\n",
    "\n",
    "# total_loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(training_args.device)\n",
    "autocast = get_autocast(training_args.precision)\n",
    "\n",
    "optical_encoder = model.module.optical_encoder.eval()\n",
    "radar_encoder = model.module.radar_encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 990/1537 [17:07<04:35,  1.98it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dict_data = {}\n",
    "for split in ['train', 'test']:\n",
    "    split_dict = dict(radar_feature=[], optical_feature=[], label=[])\n",
    "    dataloader = data[split].dataloader\n",
    "    for i, batch in enumerate(tqdm(dataloader)):\n",
    "        images, radar, label = batch['image'], batch['radar'], batch['label']\n",
    "        images = images.to(device=device, non_blocking=True)\n",
    "        radar = radar.to(device=device, non_blocking=True)\n",
    "\n",
    "        with torch.no_grad(), autocast():\n",
    "            optical_features = optical_encoder(images, return_dict=True)\n",
    "            radar_features = radar_encoder(radar, return_dict=True)\n",
    "            split_dict['radar_feature'].append(radar_features['cls_token'].detach().cpu().numpy())\n",
    "            split_dict['optical_feature'].append(optical_features['cls_token'].detach().cpu().numpy())\n",
    "            split_dict['label'].append(label.numpy())\n",
    "    split_dict['radar_feature'] = np.concatenate(split_dict['radar_feature'], axis=0)\n",
    "    split_dict['optical_feature'] = np.concatenate(split_dict['optical_feature'], axis=0)\n",
    "    split_dict['label'] = np.concatenate(split_dict['label'], axis=0)\n",
    "    dict_data[split] = split_dict\n",
    "pickle.dump(dict_data, open(f'./results/{exp_name}.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 384)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dict['radar_feature'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
