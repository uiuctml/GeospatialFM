{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- eval:\n",
    "    - test-time and train-time feed-forward\n",
    "    - channel mask and recon\n",
    "    - patch_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haozhesi/anaconda3/envs/sat/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from GeospatialFM.models.channel_vit import ChannelViTEncoder\n",
    "from GeospatialFM.models.vision_transformer import ViTEncoder, ViTDecoder\n",
    "import torch\n",
    "from GeospatialFM.models.mae import CrossModalMAEViT\n",
    "from GeospatialFM.loss.mae_loss import SpectralInterpolationLoss, MAELoss\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "optical_sample = torch.randn(2, 13, 224, 224)\n",
    "radar_sample = torch.randn(2, 2, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "optical_encoder = ChannelViTEncoder(in_chans=13, channel_pool='max')\n",
    "decoder = ViTDecoder(out_chans=15)\n",
    "radar_encoder = ViTEncoder(in_chans=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = optical_encoder.forward_encoder(optical_sample, 0.75, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 50, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = decoder.forward_decoder(output[0], output[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.076923076923077"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optical_encoder.num_patches / 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = CrossModalMAEViT(optical_encoder, radar_encoder, decoder, decoder).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = mae(optical_sample, radar_sample, 0.75, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['optical_mask', 'radar_mask', 'optical_recon', 'radar_recon', 'optical_target', 'radar_target', 'optical_cls_token', 'radar_cls_token', 'logit_scale', 'optical_channel_mask'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 196, 3840]), torch.Size([2, 196, 3328]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['optical_recon'].shape, out['optical_target'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1977e+00, -5.5180e-01, -2.4375e-01,  ...,  6.4409e-01,\n",
       "           7.9837e-01, -5.1097e-01],\n",
       "         [ 1.7075e+00,  6.0347e-02, -8.4704e-03,  ..., -1.2083e+00,\n",
       "           4.8129e-02,  3.1424e-01],\n",
       "         [ 1.8514e-01, -1.2083e+00,  8.6367e-01,  ..., -1.3438e-01,\n",
       "          -1.0370e-01,  7.4731e-01],\n",
       "         ...,\n",
       "         [-4.1498e-01, -2.0958e+00,  1.4300e-04,  ...,  1.3914e+00,\n",
       "          -6.9633e-01, -7.6774e-01],\n",
       "         [ 8.8051e-01,  2.4801e-01,  8.6115e-01,  ...,  1.2676e+00,\n",
       "          -2.8543e-02,  8.5104e-01],\n",
       "         [-6.4284e-01,  5.7437e-01, -1.4108e+00,  ..., -5.7488e-01,\n",
       "          -1.0415e+00,  1.1898e+00]],\n",
       "\n",
       "        [[-2.7266e-01, -5.6392e-01,  5.7947e-01,  ...,  3.4807e-01,\n",
       "           5.6105e-02,  2.2259e+00],\n",
       "         [-3.9405e-01,  1.3019e+00, -6.7917e-01,  ...,  1.1674e+00,\n",
       "          -1.5613e+00, -1.2703e+00],\n",
       "         [ 3.2976e-01, -1.6983e+00, -2.2353e-01,  ..., -2.8816e-01,\n",
       "           3.7322e-01,  8.0427e-02],\n",
       "         ...,\n",
       "         [ 8.8603e-01, -9.7973e-01, -7.0174e-01,  ..., -1.9549e+00,\n",
       "          -9.1999e-02,  2.3069e+00],\n",
       "         [ 3.6492e-01,  8.2506e-01, -3.5023e-01,  ..., -1.1555e-01,\n",
       "          -5.1813e-01, -9.1756e-01],\n",
       "         [ 3.8017e-02,  2.2479e-01, -1.3358e+00,  ..., -1.9831e-01,\n",
       "           4.6693e-01, -1.7847e-01]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optical_sample[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3328]), torch.Size([2, 196]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['optical_channel_mask'].shape, out['optical_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['optical_channel_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['optical_channel_mask'][0].reshape(256, 13)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 196, 3328])\n",
      "torch.Size([2, 196, 3328])\n",
      "torch.Size([2, 3328])\n",
      "tensor(3186.9939, grad_fn=<SumBackward0>) tensor(3584.)\n",
      "torch.Size([2, 196, 3328])\n",
      "torch.Size([2, 196, 3328])\n",
      "torch.Size([2, 3328])\n",
      "tensor(3181.5608, grad_fn=<SumBackward0>) tensor(3584.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'optical_channel_mse': tensor(0.8892, grad_fn=<MulBackward0>),\n",
       " 'radar_channel_mse': tensor(0.8877, grad_fn=<MulBackward0>)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = SpectralInterpolationLoss()\n",
    "loss(**out, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 196, 3840])\n",
      "torch.Size([2, 196])\n",
      "tensor(261.1608, grad_fn=<SumBackward0>) tensor(294.)\n",
      "torch.Size([2, 196, 3840])\n",
      "torch.Size([2, 196])\n",
      "tensor(260.6951, grad_fn=<SumBackward0>) tensor(294.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'optical_mse': tensor(0.8883, grad_fn=<MulBackward0>),\n",
       " 'radar_mse': tensor(0.8867, grad_fn=<MulBackward0>)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = MAELoss()\n",
    "loss(**out, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optical_mask torch.Size([2, 196])\n",
      "radar_mask torch.Size([2, 196])\n",
      "optical_recon torch.Size([2, 196, 3840])\n",
      "radar_recon torch.Size([2, 196, 3840])\n",
      "optical_target torch.Size([2, 196, 3328])\n",
      "radar_target torch.Size([2, 196, 512])\n",
      "optical_cls_token torch.Size([2, 768])\n",
      "radar_cls_token torch.Size([2, 768])\n",
      "logit_scale torch.Size([])\n",
      "optical_channel_mask torch.Size([2, 3328])\n"
     ]
    }
   ],
   "source": [
    "for key in out.keys():\n",
    "    print(key, out[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3840 / 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "optical_target = out['optical_target']\n",
    "optical_recon = out['optical_recon']\n",
    "radar_recon = out['radar_recon']\n",
    "B, L, D = optical_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _forward_channel_mse_one_modal(recon, target, mask):\n",
    "    B, L, D = target.shape\n",
    "    recon = recon[:, :, :D]\n",
    "    loss = (recon - target).abs()\n",
    "    loss = loss.mean(dim=1)\n",
    "    if mask.sum() == 0:\n",
    "        return loss.mean() # if no mask, mean loss on all channels\n",
    "    loss = (loss * mask).sum() / mask.sum()  # mean loss on removed patches\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 196, 3840]), torch.Size([2, 196, 3328]))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optical_recon.shape, optical_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = out['optical_channel_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3328]) tensor(0.8925, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "_unimodal_channel_loss(optical_recon, optical_target, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optical_loss = optical_recon[:, :, :D]\n",
    "radar_recon_o = radar_recon[:, :, :D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_mask = mask.unsqueeze(1).unsqueeze(1).expand(B, L, 256, -1).reshape(B, L, D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 196, 3328])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon_channels = (expanded_mask * radar_recon_o)\n",
    "recon_channels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
