MODEL:
  architecture: mm_lr_vit_base_patch16_224
  MULTI_MODAL:
    use_head: true
    head_kwargs:
      use_bias: true
DATASET:
  name: So2Sat
TRAINER:
  # Training related
  num_train_epochs: 20
  per_device_train_batch_size: 128
  per_device_eval_batch_size: 128
  gradient_accumulation_steps: 4
  learning_rate: 1e-3
  weight_decay: 0.05
  # dataloader
  dataloader_num_workers: 8
  dataloader_pin_memory: true
  dataloader_drop_last: false
  # Logging
  report_to: wandb
  logging_steps: 50
  # optimizer
  optim: adamw_torch
  lr_scheduler_type: cosine
  warmup_epochs: 4
  # Other
  seed: 0
  # ckpt
  save_frequency: 10
