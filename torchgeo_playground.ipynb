{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "\n",
    "from GeospatialFM.data import get_datasets\n",
    "from GeospatialFM.models import *\n",
    "# from utils import load_config\n",
    "from torchgeo.samplers import RandomGeoSampler\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from GeospatialFM.utils import setup, get_eval_fn, get_data, init_distributed_device\n",
    "from GeospatialFM.data import *\n",
    "from GeospatialFM.models import *\n",
    "from GeospatialFM.loss import *\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.data import ConcatDataset\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'exp_name': None,\n",
    "        'config_file': 'GeospatialFM/configs/pretrain_cvit.yaml',\n",
    "        'opts': None, \n",
    "        'save_config': False}\n",
    "args = argparse.Namespace(**args)\n",
    "args.debug = True\n",
    "args.finetune = False\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = init_distributed_device(args)\n",
    "cfg, _ = setup(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.DATASET['train_transforms']['normalize'] = True\n",
    "cfg.DATASET['train_transforms']['standardize'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(cfg)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = iter(data['test'].dataloader).__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = construct_mae(cfg.MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "device_ids = [0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "model = torch.nn.DataParallel(model, device_ids=device_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = get_loss_list(cfg.LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = sample['image'].to(device, non_blocking=True)\n",
    "# radar = sample['radar'].to(device, non_blocking=True)\n",
    "image = sample['image']\n",
    "radar = sample['radar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_out = model(image, radar)\n",
    "# logit_scale = model_out.get(\"logit_scale\").mean()\n",
    "# model_out['logit_scale'] = logit_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points = [[20, 193], [35, 180], [55, 150], [130, 180], [95, 140], [30, 25], [80, 30]]\n",
    "points = [[45, 10], [45, 20]]\n",
    "cross_length = 5\n",
    "img_id = 100\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "color = ['r', 'g', 'b', 'cyan', 'orange', 'purple', 'brown']\n",
    "for c, point in enumerate(points):\n",
    "    curve = image[img_id, :, point[0], point[1]].detach().cpu().numpy()\n",
    "    curve = np.delete(curve, 10)\n",
    "    plt.plot(np.arange(12), curve, color[c])\n",
    "vis_img = image[img_id, [3, 2, 1], :, :].detach().cpu().numpy().transpose(1, 2, 0)\n",
    "# normalize each channel\n",
    "vis_img = (vis_img - vis_img.min()) / (vis_img.max() - vis_img.min())\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(vis_img)\n",
    "# draw a cross at the point\n",
    "for c, point in enumerate(points):\n",
    "    plt.plot([point[1] - cross_length, point[1] + cross_length], [point[0], point[0]],  color[c]) \n",
    "    # Draw vertical line of the cross\n",
    "    plt.plot([point[1], point[1]], [point[0] - cross_length, point[0] + cross_length],  color[c]) \n",
    "# plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points = [[20, 193], [35, 180], [55, 150], [130, 180], [95, 140], [30, 25], [80, 30]]\n",
    "points = [[45, 10], [45, 20]]\n",
    "cross_length = 5\n",
    "img_id = 150\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "color = ['r', 'g', 'b', 'cyan', 'orange', 'purple', 'brown']\n",
    "for c, point in enumerate(points):\n",
    "    curve = radar[img_id, :, point[0], point[1]].detach().cpu().numpy()\n",
    "    # curve = np.delete(curve, 10)\n",
    "    plt.plot(np.arange(2), curve, color[c])\n",
    "vis_img = radar[img_id, [0], :, :].detach().cpu().numpy().transpose(1, 2, 0)\n",
    "# normalize each channel\n",
    "vis_img = (vis_img - vis_img.min()) / (vis_img.max() - vis_img.min())\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(vis_img)\n",
    "# draw a cross at the point\n",
    "for c, point in enumerate(points):\n",
    "    plt.plot([point[1] - cross_length, point[1] + cross_length], [point[0], point[0]],  color[c]) \n",
    "    # Draw vertical line of the cross\n",
    "    plt.plot([point[1], point[1]], [point[0] - cross_length, point[0] + cross_length],  color[c]) \n",
    "# plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GeospatialFM.models.costum_layers import *\n",
    "import torch\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.randn(2, 13, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_embedding = PatchEmbedPerChannel(in_chans=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tokens = dict()\n",
    "extra_tokens[\"channels\"] = torch.tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]])\n",
    "out = patch_embedding(sample, extra_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collpase_channels(out[0], 'mean').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13*0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sample\n",
    "B, Cin, H, W = x.shape\n",
    "# Note: The current number of channels (Cin) can be smaller or equal to in_chans\n",
    "len_keep = int(Cin * 0.4)\n",
    "\n",
    "noise = torch.rand(B, Cin, device=x.device)  # noise in [0, 1]\n",
    "# sort noise for each sample\n",
    "ids_shuffle = torch.argsort(noise, dim=1)  # ascend: small is keep, large is remove\n",
    "ids_restore = torch.argsort(ids_shuffle, dim=1)\n",
    "\n",
    "# keep the first subset\n",
    "ids_keep = ids_shuffle[:, :len_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_keep.unsqueeze(-1).unsqueeze(-1).repeat(1, 5, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_keep.shape\n",
    "# sample corresponding channels from ce\n",
    "new_ce = torch.gather(ce, 2, ids_keep.unsqueeze(1).repeat(1, ce.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ce[0, :5, 0], ids_keep[0, 0], ce[0, :5, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ce[0, :5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce[0, :5, 2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather the C dim of the batch of the images in shape B x C x H x W following the index of ids_keep\n",
    "x_keep = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).unsqueeze(-1).repeat(1, 1, *x.shape[-2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_keep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the binary mask: 0 is keep, 1 is remove\n",
    "mask = torch.ones([B, Cin], device=x.device)\n",
    "mask[:, :len_keep] = 0\n",
    "# unshuffle to get the binary mask\n",
    "mask = torch.gather(mask, dim=1, index=ids_restore)\n",
    "# Per batch channel sampling\n",
    "        # Note this may be slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = torch.rand((2, 3, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_chans = 13\n",
    "embed_dim = 768\n",
    "patch_size = 16\n",
    "sample = torch.randn(320, 13, 224, 224)\n",
    "proj = nn.Conv2d(\n",
    "    in_chans,\n",
    "    embed_dim*in_chans,\n",
    "    kernel_size=(patch_size, patch_size),\n",
    "    stride=(patch_size, patch_size),\n",
    "    groups=in_chans,\n",
    ")  # CHANGED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj2 = nn.Conv2d(\n",
    "    in_chans,\n",
    "    embed_dim,\n",
    "    kernel_size=(patch_size, patch_size),\n",
    "    stride=(patch_size, patch_size),\n",
    "    bias=False\n",
    ")  # CHANGED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj3 = nn.Conv3d(\n",
    "    1,\n",
    "    embed_dim*in_chans,\n",
    "    kernel_size=(1, patch_size, patch_size),\n",
    "    stride=(1, patch_size, patch_size),\n",
    "    bias=False\n",
    ")  # CHANGED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[p for p in proj.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[p.numel() for p in proj2.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of parameters\n",
    "w1 = sum(p.numel() for p in proj.parameters())\n",
    "w2 = sum(p.numel() for p in proj2.parameters())\n",
    "w3 = sum(p.numel() for p in proj3.parameters())\n",
    "w1-w2, w3-w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = proj.weight.flatten().shape[0]\n",
    "w2 = proj2.weight.flatten().shape[0]\n",
    "w3 = proj3.weight.flatten().shape[0]\n",
    "w1-w2, w3-w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = proj.bias.flatten().shape[0]\n",
    "b2 = proj2.bias.flatten().shape[0]\n",
    "b3 = proj3.bias.flatten().shape[0]\n",
    "w1-w2, w3-w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj.to('cuda:1')\n",
    "proj2.to('cuda:1')\n",
    "proj3.to('cuda:1')\n",
    "sample = sample.to('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the timw of the forward pass\n",
    "import time\n",
    "start = time.time()\n",
    "out1 = proj(sample).cpu()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "start = time.time()\n",
    "out2 = proj2(sample).cpu()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "start = time.time()     \n",
    "out3 = proj3(sample.unsqueeze(1)).cpu()\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[:, torch.tensor([0, 1, 11])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.uniform(0.25, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.randn(2, 1, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = nn.Conv3d(\n",
    "    1,\n",
    "    1024,\n",
    "    kernel_size=(1, 4, 4),\n",
    "    stride=(1, 4, 4),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj2 = nn.Conv3d(\n",
    "    1024,\n",
    "    768, \n",
    "    kernel_size=(1, 4, 4),\n",
    "    stride=(1, 4, 4),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj3 = nn.Conv3d(\n",
    "    768,\n",
    "    768, \n",
    "    kernel_size=(1, 1, 1),\n",
    "    stride=(1, 1, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj3(proj2(proj(sample.unsqueeze(1)))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 768\n",
    "proj = nn.Conv3d(\n",
    "        embed_dim*2,\n",
    "        embed_dim,\n",
    "        kernel_size=(1, 1, 1),\n",
    "        stride=(1, 1, 1),\n",
    "    )\n",
    "w = sum(p.numel() for p in proj.parameters())\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2*embed_dim**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = 'results/cache/BigEarthNet_vit_base_patch16_224_mae_base_finetune_OPTICAL/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(cache_path, split):\n",
    "    # list all files in cache_path containing split\n",
    "    cache_files = [f for f in os.listdir(cache_path) if split in f and f.endswith('.pkl')]\n",
    "    cache_files.sort()\n",
    "    features = dict(label=[], img_feature=[])\n",
    "    for f_name in cache_files:\n",
    "        print(f_name)\n",
    "        with open(os.path.join(cache_path, f_name), 'rb') as f:\n",
    "            chunk_features = pickle.load(f)\n",
    "            print(chunk_features)\n",
    "            features['label'].append(chunk_features['label'])\n",
    "            features['img_feature'].append(chunk_features['img_feature'])\n",
    "    print(features['label'])\n",
    "    features['label'] = torch.cat(features['label'], dim=0)\n",
    "    features['img_feature'] = torch.cat(features['img_feature'], dim=0)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_features(cache_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelINN(nn.Module):\n",
    "    def __init__(self, n_nodes, out_channels, kernel_size, stride, padding=0):\n",
    "        super(ChannelINN, self).__init__()\n",
    "        self.conv = nn.Conv3d(1, n_nodes*out_channels, kernel_size, stride, padding)\n",
    "        self.n_nodes = n_nodes\n",
    "        self.out_channels = out_channels\n",
    "        self._x = torch.linspace(0, 1, n_nodes)\n",
    "    \n",
    "    # def _interpolate(self, x, idx):\n",
    "    def _intergral(self, x, idx):\n",
    "        pass\n",
    "        # x in shape B x n_nodes x C_out x H x W\n",
    "        \n",
    " \n",
    "    def forward(self, x, x_idx):\n",
    "        # x in shape B x 1 x C x H x W\n",
    "        assert x_idx.shape[0] == x.shape[2]\n",
    "        x = self.conv(x) # B x n_nodes*out_channels C x H x W\n",
    "        B, _, C, H, W = x.shape\n",
    "        x = x.view(B, self.n_nodes, self.out_channels, C, H, W)\n",
    "        x_ = torch.zeros(B, self.out_channels, C, H, W, device=x.device)\n",
    "        for i in range(C):\n",
    "            idx = x_idx[i]\n",
    "            fx = x[:, :, :, i, :, :]\n",
    "            x_[:, :, i, :, :] = self._interpolate(fx, idx)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChannelINN(20, 768, (1, 16, 16), (1, 16, 16))\n",
    "sample = torch.randn(2, 13, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(sample.unsqueeze(1), torch.arange(13)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haozhesi/anaconda3/envs/sat/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torchgeo.datamodules as tgdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = getattr(tgdm, 'EuroSATDataModule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1354.4055, 1118.2440, 1042.9298,  947.6262, 1199.4729, 1999.7909,\n",
       "        2369.2229, 2296.8262,  732.0834,   12.1133, 1819.0103, 1118.9240,\n",
       "        2594.1409])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 245.7176,  333.0078,  395.0925,  593.7505,  566.4170,  861.1840,\n",
       "        1086.6313, 1117.9817,  404.9198,    4.7758, 1002.5877,  761.3032,\n",
       "        1231.5858])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = tgdm.So2SatDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(255))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.mean, dm.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = tgdm.BigEarthNetDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(255))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.mean, dm.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'bands': ['S2_B02', 'S2_B03', 'S2_B04', 'S2_B05', 'S2_B06', 'S2_B07', 'S2_B08', 'S2_B8A', 'S2_B11', 'S2_B12'], 'version': '3_culture_10', 'pad_s2': True, 'root': './data/geospatial/So2Sat'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = tgdm.So2SatDataModule(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(255))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.mean, dm.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-16.128097534179688"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(1).uniform_(float(-30), float(30)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.random' has no attribute 'choice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.random' has no attribute 'choice'"
     ]
    }
   ],
   "source": [
    "torch.random.choice([0, 1]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(270.)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "degrees = [0, 90, 180, 270]\n",
    "torch.tensor(random.choice(degrees), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
