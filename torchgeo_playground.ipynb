{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haozhesi/anaconda3/envs/sat/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "\n",
    "from GeospatialFM.data import get_datasets\n",
    "from GeospatialFM.models import *\n",
    "# from utils import load_config\n",
    "from torchgeo.samplers import RandomGeoSampler\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from GeospatialFM.utils import setup, get_eval_fn, get_data, init_distributed_device\n",
    "from GeospatialFM.data import *\n",
    "from GeospatialFM.models import *\n",
    "from GeospatialFM.loss import *\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.data import ConcatDataset\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(exp_name=None, config_file='GeospatialFM/configs/pretrain_cvit.yaml', opts=None, save_config=False, debug=True, finetune=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = {'exp_name': None,\n",
    "        'config_file': 'GeospatialFM/configs/pretrain_cvit.yaml',\n",
    "        'opts': None, \n",
    "        'save_config': False}\n",
    "args = argparse.Namespace(**args)\n",
    "args.debug = True\n",
    "args.finetune = False\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Namespace' object has no attribute 'rank'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cfg, _ \u001b[38;5;241m=\u001b[39m \u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dropbox/GeospatialFM/GeospatialFM/utils/configs.py:57\u001b[0m, in \u001b[0;36msetup\u001b[0;34m(args, wandb)\u001b[0m\n\u001b[1;32m     55\u001b[0m cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRAINER\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_dir\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATASET\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNAME\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     56\u001b[0m cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRAINER\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogging_dir\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATASET\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNAME\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_master\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     58\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRAINER\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_dir\u001b[39m\u001b[38;5;124m'\u001b[39m], exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     59\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRAINER\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogging_dir\u001b[39m\u001b[38;5;124m'\u001b[39m], exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Dropbox/GeospatialFM/GeospatialFM/utils/distributed.py:16\u001b[0m, in \u001b[0;36mis_master\u001b[0;34m(args, local)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_master\u001b[39m(args, local\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m is_local_master(args) \u001b[38;5;28;01mif\u001b[39;00m local \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mis_global_master\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dropbox/GeospatialFM/GeospatialFM/utils/distributed.py:8\u001b[0m, in \u001b[0;36mis_global_master\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_global_master\u001b[39m(args):\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrank\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Namespace' object has no attribute 'rank'"
     ]
    }
   ],
   "source": [
    "device = init_distributed_device(args)\n",
    "cfg, _ = setup(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.DATASET['train_transforms']['normalize'] = True\n",
    "cfg.DATASET['train_transforms']['standardize'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(cfg)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = iter(data['test'].dataloader).__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = construct_mae(cfg.MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "device_ids = [0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "model = torch.nn.DataParallel(model, device_ids=device_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = get_loss_list(cfg.LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = sample['image'].to(device, non_blocking=True)\n",
    "# radar = sample['radar'].to(device, non_blocking=True)\n",
    "image = sample['image']\n",
    "radar = sample['radar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_out = model(image, radar)\n",
    "# logit_scale = model_out.get(\"logit_scale\").mean()\n",
    "# model_out['logit_scale'] = logit_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points = [[20, 193], [35, 180], [55, 150], [130, 180], [95, 140], [30, 25], [80, 30]]\n",
    "points = [[45, 10], [45, 20]]\n",
    "cross_length = 5\n",
    "img_id = 100\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "color = ['r', 'g', 'b', 'cyan', 'orange', 'purple', 'brown']\n",
    "for c, point in enumerate(points):\n",
    "    curve = image[img_id, :, point[0], point[1]].detach().cpu().numpy()\n",
    "    curve = np.delete(curve, 10)\n",
    "    plt.plot(np.arange(12), curve, color[c])\n",
    "vis_img = image[img_id, [3, 2, 1], :, :].detach().cpu().numpy().transpose(1, 2, 0)\n",
    "# normalize each channel\n",
    "vis_img = (vis_img - vis_img.min()) / (vis_img.max() - vis_img.min())\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(vis_img)\n",
    "# draw a cross at the point\n",
    "for c, point in enumerate(points):\n",
    "    plt.plot([point[1] - cross_length, point[1] + cross_length], [point[0], point[0]],  color[c]) \n",
    "    # Draw vertical line of the cross\n",
    "    plt.plot([point[1], point[1]], [point[0] - cross_length, point[0] + cross_length],  color[c]) \n",
    "# plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points = [[20, 193], [35, 180], [55, 150], [130, 180], [95, 140], [30, 25], [80, 30]]\n",
    "points = [[45, 10], [45, 20]]\n",
    "cross_length = 5\n",
    "img_id = 150\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "color = ['r', 'g', 'b', 'cyan', 'orange', 'purple', 'brown']\n",
    "for c, point in enumerate(points):\n",
    "    curve = radar[img_id, :, point[0], point[1]].detach().cpu().numpy()\n",
    "    # curve = np.delete(curve, 10)\n",
    "    plt.plot(np.arange(2), curve, color[c])\n",
    "vis_img = radar[img_id, [0], :, :].detach().cpu().numpy().transpose(1, 2, 0)\n",
    "# normalize each channel\n",
    "vis_img = (vis_img - vis_img.min()) / (vis_img.max() - vis_img.min())\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(vis_img)\n",
    "# draw a cross at the point\n",
    "for c, point in enumerate(points):\n",
    "    plt.plot([point[1] - cross_length, point[1] + cross_length], [point[0], point[0]],  color[c]) \n",
    "    # Draw vertical line of the cross\n",
    "    plt.plot([point[1], point[1]], [point[0] - cross_length, point[0] + cross_length],  color[c]) \n",
    "# plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haozhesi/anaconda3/envs/sat/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from GeospatialFM.models.costum_layers import *\n",
    "import torch\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.randn(2, 13, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_embedding = PatchEmbedPerChannel(in_chans=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tokens = dict()\n",
    "extra_tokens[\"channels\"] = torch.tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]])\n",
    "out = patch_embedding(sample, extra_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collpase_channels(out[0], 'mean').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 13])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.25"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13*0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sample\n",
    "B, Cin, H, W = x.shape\n",
    "# Note: The current number of channels (Cin) can be smaller or equal to in_chans\n",
    "len_keep = int(Cin * 0.4)\n",
    "\n",
    "noise = torch.rand(B, Cin, device=x.device)  # noise in [0, 1]\n",
    "# sort noise for each sample\n",
    "ids_shuffle = torch.argsort(noise, dim=1)  # ascend: small is keep, large is remove\n",
    "ids_restore = torch.argsort(ids_shuffle, dim=1)\n",
    "\n",
    "# keep the first subset\n",
    "ids_keep = ids_shuffle[:, :len_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5,  5,  5,  ...,  5,  5,  5],\n",
       "          [ 5,  5,  5,  ...,  5,  5,  5],\n",
       "          [ 5,  5,  5,  ...,  5,  5,  5],\n",
       "          ...,\n",
       "          [ 5,  5,  5,  ...,  5,  5,  5],\n",
       "          [ 5,  5,  5,  ...,  5,  5,  5],\n",
       "          [ 5,  5,  5,  ...,  5,  5,  5]],\n",
       "\n",
       "         [[ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          ...,\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1]],\n",
       "\n",
       "         [[ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          ...,\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          ...,\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6]],\n",
       "\n",
       "         [[12, 12, 12,  ..., 12, 12, 12],\n",
       "          [12, 12, 12,  ..., 12, 12, 12],\n",
       "          [12, 12, 12,  ..., 12, 12, 12],\n",
       "          ...,\n",
       "          [12, 12, 12,  ..., 12, 12, 12],\n",
       "          [12, 12, 12,  ..., 12, 12, 12],\n",
       "          [12, 12, 12,  ..., 12, 12, 12]],\n",
       "\n",
       "         [[ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          ...,\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0]]],\n",
       "\n",
       "\n",
       "        [[[ 2,  2,  2,  ...,  2,  2,  2],\n",
       "          [ 2,  2,  2,  ...,  2,  2,  2],\n",
       "          [ 2,  2,  2,  ...,  2,  2,  2],\n",
       "          ...,\n",
       "          [ 2,  2,  2,  ...,  2,  2,  2],\n",
       "          [ 2,  2,  2,  ...,  2,  2,  2],\n",
       "          [ 2,  2,  2,  ...,  2,  2,  2]],\n",
       "\n",
       "         [[11, 11, 11,  ..., 11, 11, 11],\n",
       "          [11, 11, 11,  ..., 11, 11, 11],\n",
       "          [11, 11, 11,  ..., 11, 11, 11],\n",
       "          ...,\n",
       "          [11, 11, 11,  ..., 11, 11, 11],\n",
       "          [11, 11, 11,  ..., 11, 11, 11],\n",
       "          [11, 11, 11,  ..., 11, 11, 11]],\n",
       "\n",
       "         [[ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          ...,\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          ...,\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1]],\n",
       "\n",
       "         [[12, 12, 12,  ..., 12, 12, 12],\n",
       "          [12, 12, 12,  ..., 12, 12, 12],\n",
       "          [12, 12, 12,  ..., 12, 12, 12],\n",
       "          ...,\n",
       "          [12, 12, 12,  ..., 12, 12, 12],\n",
       "          [12, 12, 12,  ..., 12, 12, 12],\n",
       "          [12, 12, 12,  ..., 12, 12, 12]],\n",
       "\n",
       "         [[ 8,  8,  8,  ...,  8,  8,  8],\n",
       "          [ 8,  8,  8,  ...,  8,  8,  8],\n",
       "          [ 8,  8,  8,  ...,  8,  8,  8],\n",
       "          ...,\n",
       "          [ 8,  8,  8,  ...,  8,  8,  8],\n",
       "          [ 8,  8,  8,  ...,  8,  8,  8],\n",
       "          [ 8,  8,  8,  ...,  8,  8,  8]]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_keep.unsqueeze(-1).unsqueeze(-1).repeat(1, 5, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_keep.shape\n",
    "# sample corresponding channels from ce\n",
    "new_ce = torch.gather(ce, 2, ids_keep.unsqueeze(1).repeat(1, ce.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0149,  0.0129,  0.0069, -0.0358,  0.0500],\n",
       "        grad_fn=<SelectBackward0>),\n",
       " tensor(2),\n",
       " tensor([ 0.0149,  0.0129,  0.0069, -0.0358,  0.0500],\n",
       "        grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ce[0, :5, 0], ids_keep[0, 0], ce[0, :5, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ce[0, :5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce[0, :5, 2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather the C dim of the batch of the images in shape B x C x H x W following the index of ids_keep\n",
    "x_keep = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).unsqueeze(-1).repeat(1, 1, *x.shape[-2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 224, 224])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_keep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the binary mask: 0 is keep, 1 is remove\n",
    "mask = torch.ones([B, Cin], device=x.device)\n",
    "mask[:, :len_keep] = 0\n",
    "# unshuffle to get the binary mask\n",
    "mask = torch.gather(mask, dim=1, index=ids_restore)\n",
    "# Per batch channel sampling\n",
    "        # Note this may be slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  1,  6, 12,  0],\n",
       "        [ 2, 11,  1, 12,  8]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = torch.rand((2, 3, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_chans = 13\n",
    "embed_dim = 768\n",
    "patch_size = 16\n",
    "\n",
    "proj = nn.Conv2d(\n",
    "    in_chans,\n",
    "    embed_dim*in_chans,\n",
    "    kernel_size=(patch_size, patch_size),\n",
    "    stride=(patch_size, patch_size),\n",
    "    groups=in_chans,\n",
    ")  # CHANGED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj2 = nn.Conv2d(\n",
    "    in_chans,\n",
    "    embed_dim,\n",
    "    kernel_size=(patch_size, patch_size),\n",
    "    stride=(patch_size, patch_size),\n",
    ")  # CHANGED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9216"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the number of parameters\n",
    "w1 = sum(p.numel() for p in proj.parameters())\n",
    "w2 = sum(p.numel() for p in proj2.parameters())\n",
    "w1-w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 13, 768, 14, 14])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj(sample).view(-1, in_chans, embed_dim, 14, 14).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 13, 224, 224])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 224, 224])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[:, torch.tensor([0, 1, 11])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
