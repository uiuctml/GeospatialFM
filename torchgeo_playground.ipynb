{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haozhesi/anaconda3/envs/sat/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "\n",
    "from GeospatialFM.data import get_datasets\n",
    "from GeospatialFM.models import *\n",
    "# from utils import load_config\n",
    "from torchgeo.samplers import RandomGeoSampler\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from GeospatialFM.utils import setup, get_eval_fn\n",
    "from GeospatialFM.data import *\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.data import ConcatDataset\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_model = smp.Unet(\n",
    "    encoder_name='resnet50',\n",
    "    encoder_weights=None,\n",
    "    in_channels=13,\n",
    "    classes=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 23539392\n"
     ]
    }
   ],
   "source": [
    "seg_model.encoder\n",
    "# find the number of parameters\n",
    "num_params = sum(p.numel() for p in seg_model.encoder.parameters() if p.requires_grad)\n",
    "print(f'Number of parameters: {num_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(exp_name=None, config_file='GeospatialFM/configs/bigearthnet/bn_rn50_dino.yaml', opts=None, save_config=False, debug=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = {'exp_name': None,\n",
    "        'config_file': 'GeospatialFM/configs/bigearthnet/bn_rn50_dino.yaml',\n",
    "        'opts': None, \n",
    "        'save_config': False}\n",
    "args = argparse.Namespace(**args)\n",
    "args.debug = True\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg, _ = setup(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root': './data/geospatial', 'name': 'BigEarthNet', 'kwargs': {'bands': 's2', 'num_classes': 19, 'pad_s2': True}, 'train_transforms': {'crop_size': 224, 'hflip_prob': 0.5, 'normalize': False, 'standardize': True}, 'eval_transforms': {'crop_size': 224, 'resize_size': 256, 'normalize': False, 'standardize': True}, 'eval_metric': 'classification', 'use_train_transform': True, 'train_frac': 0.1, 'train_split': 'trainval'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg['DATASET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = get_datasets(cfg['DATASET'])\n",
    "training_args = TrainingArguments(**cfg['TRAINER'])\n",
    "model = construct_model(cfg['MODEL'])\n",
    "model = model.to(device)\n",
    "compute_metrics = get_eval_fn(cfg['DATASET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39341, 125866)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 23578323\n"
     ]
    }
   ],
   "source": [
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Number of parameters: {num_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model.base_model's weights to segmentation model encoder\n",
    "seg_model.encoder.load_state_dict(model.base_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-9.2418e-03, -1.0045e-02, -2.0850e-02,  ...,  9.5041e-03,\n",
       "           -4.4111e-02, -1.3601e-02],\n",
       "          [-9.6233e-04, -1.4055e-02, -3.4424e-02,  ..., -1.0499e-02,\n",
       "           -3.6969e-02, -1.3789e-02],\n",
       "          [ 1.4830e-03, -2.9535e-03, -3.3906e-02,  ..., -2.5526e-02,\n",
       "           -2.8786e-02, -1.7858e-02],\n",
       "          ...,\n",
       "          [ 4.5780e-02,  2.8101e-02, -7.5487e-03,  ..., -1.4892e-02,\n",
       "           -1.8777e-02,  4.1441e-04],\n",
       "          [-9.1902e-04, -1.7040e-02, -2.6475e-02,  ..., -1.2081e-02,\n",
       "           -4.0107e-02, -2.9371e-02],\n",
       "          [ 3.8115e-03, -1.3840e-02, -3.6461e-02,  ...,  4.6202e-03,\n",
       "           -3.7808e-02, -2.7769e-02]],\n",
       "\n",
       "         [[ 4.5979e-02,  1.8778e-02,  1.7668e-03,  ...,  1.8057e-02,\n",
       "           -3.5278e-03,  3.0955e-02],\n",
       "          [ 3.4729e-02,  1.9919e-02, -1.5212e-02,  ..., -4.6602e-03,\n",
       "           -1.9585e-02,  2.5568e-02],\n",
       "          [ 4.1330e-02,  1.1526e-02, -2.4713e-02,  ..., -4.7586e-02,\n",
       "           -1.5346e-02,  3.0014e-02],\n",
       "          ...,\n",
       "          [ 7.1903e-02,  3.5796e-02, -3.0330e-02,  ..., -6.1217e-02,\n",
       "           -1.6289e-02,  4.4941e-02],\n",
       "          [ 3.4417e-02,  1.3536e-02, -3.7246e-02,  ..., -3.9665e-02,\n",
       "           -3.8553e-02,  1.8246e-02],\n",
       "          [ 3.4762e-02,  2.6327e-02, -2.2951e-02,  ...,  1.1436e-03,\n",
       "           -5.4971e-03,  1.6642e-02]],\n",
       "\n",
       "         [[ 1.4746e-02, -1.3944e-02, -3.5599e-02,  ..., -1.6982e-02,\n",
       "           -2.7319e-02,  3.5649e-03],\n",
       "          [ 1.4082e-03, -1.6247e-02, -4.9566e-02,  ..., -4.3322e-02,\n",
       "           -3.8222e-02,  1.2213e-02],\n",
       "          [-5.3261e-03, -2.5558e-02, -6.7742e-02,  ..., -9.1828e-02,\n",
       "           -4.3960e-02,  1.5194e-02],\n",
       "          ...,\n",
       "          [ 3.0071e-02, -1.8110e-02, -1.0148e-01,  ..., -1.4105e-01,\n",
       "           -5.0090e-02,  1.9930e-02],\n",
       "          [ 1.4843e-02, -1.7902e-02, -8.9446e-02,  ..., -9.0642e-02,\n",
       "           -4.9822e-02, -1.6987e-03],\n",
       "          [ 2.0906e-02,  9.6359e-04, -5.4175e-02,  ..., -3.1877e-02,\n",
       "           -1.5012e-02,  2.1123e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.1780e-02,  1.1060e-02, -8.4923e-03,  ...,  3.6956e-02,\n",
       "           -1.0501e-02, -1.3299e-03],\n",
       "          [ 2.0914e-02,  8.2167e-03, -6.2480e-03,  ...,  3.2881e-02,\n",
       "           -1.2337e-02,  3.1550e-03],\n",
       "          [ 1.0123e-02,  1.2501e-02, -1.5402e-03,  ...,  3.0078e-03,\n",
       "            1.2472e-03,  2.4518e-02],\n",
       "          ...,\n",
       "          [ 6.6146e-02,  4.8085e-02,  1.2360e-02,  ...,  1.6282e-02,\n",
       "            3.4719e-03,  3.2305e-02],\n",
       "          [ 2.7564e-02,  3.3932e-02,  3.5054e-03,  ...,  2.3824e-02,\n",
       "           -4.3789e-03,  9.3819e-03],\n",
       "          [ 4.2056e-02,  2.7264e-02,  1.1725e-02,  ...,  6.1156e-02,\n",
       "           -5.9941e-04,  1.3978e-03]],\n",
       "\n",
       "         [[ 5.1347e-03, -1.1087e-02, -1.2901e-02,  ...,  1.9442e-02,\n",
       "           -2.6442e-02,  9.8096e-03],\n",
       "          [ 1.0844e-02, -8.8672e-03, -2.5259e-02,  ...,  4.3493e-03,\n",
       "           -2.3895e-02,  2.8492e-03],\n",
       "          [ 9.5128e-03,  3.6867e-04, -3.1328e-02,  ..., -1.0600e-02,\n",
       "           -1.1031e-02,  1.7145e-02],\n",
       "          ...,\n",
       "          [ 4.5660e-02,  2.7581e-02,  3.5208e-03,  ..., -1.0735e-03,\n",
       "           -1.0725e-02,  1.3193e-02],\n",
       "          [-1.7386e-02, -1.7067e-02, -3.1653e-02,  ...,  5.2336e-04,\n",
       "           -2.6189e-02, -8.2575e-03],\n",
       "          [-4.5996e-03, -1.3512e-02, -3.2545e-02,  ...,  3.5633e-02,\n",
       "           -2.0409e-02, -6.2724e-03]],\n",
       "\n",
       "         [[ 2.4111e-02, -3.8783e-03, -1.7499e-02,  ..., -2.5193e-04,\n",
       "           -2.6940e-02,  1.0575e-02],\n",
       "          [ 2.7226e-02,  8.2185e-03, -2.7365e-02,  ..., -5.1170e-03,\n",
       "           -2.8086e-02,  1.9867e-02],\n",
       "          [ 4.0227e-02,  1.9320e-02, -1.4280e-02,  ..., -2.1549e-02,\n",
       "           -1.6521e-02,  3.7569e-02],\n",
       "          ...,\n",
       "          [ 7.0752e-02,  5.3995e-02, -7.4649e-03,  ..., -1.3508e-02,\n",
       "           -1.1346e-02,  3.9250e-02],\n",
       "          [ 2.8104e-02,  1.5577e-02, -2.5372e-02,  ...,  3.0302e-03,\n",
       "           -1.3538e-02, -1.8605e-04],\n",
       "          [ 1.8118e-02,  2.1260e-02, -1.7105e-02,  ...,  5.0523e-02,\n",
       "           -9.5660e-03,  2.0148e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.3150e-02, -2.1199e-02, -2.6270e-02,  ..., -1.2738e-02,\n",
       "            4.8199e-02,  5.9942e-02],\n",
       "          [ 1.8090e-02, -9.5158e-03, -3.0424e-02,  ..., -1.5107e-02,\n",
       "            4.1180e-02,  2.1438e-02],\n",
       "          [ 1.7755e-02,  5.8312e-03, -4.0304e-02,  ...,  3.3357e-03,\n",
       "            8.7040e-02,  3.4513e-02],\n",
       "          ...,\n",
       "          [ 1.2626e-02,  4.2240e-02, -1.1150e-02,  ..., -7.0291e-02,\n",
       "            5.2566e-02,  4.1343e-02],\n",
       "          [ 1.7631e-02,  4.3412e-02,  3.2455e-02,  ..., -5.2955e-02,\n",
       "            5.0255e-02,  3.8287e-02],\n",
       "          [ 3.0160e-02,  1.0539e-02,  3.3790e-02,  ..., -3.2462e-02,\n",
       "            3.9877e-02,  5.7811e-02]],\n",
       "\n",
       "         [[-2.4753e-02, -4.1778e-02, -1.9752e-02,  ..., -3.4178e-02,\n",
       "            8.4361e-03,  3.9040e-02],\n",
       "          [-1.1082e-02, -9.7531e-03,  7.6564e-03,  ..., -5.1764e-02,\n",
       "           -3.8786e-02, -4.3574e-02],\n",
       "          [-1.2865e-03,  4.2607e-02,  4.7385e-02,  ..., -2.0311e-02,\n",
       "           -2.6655e-02, -6.3886e-02],\n",
       "          ...,\n",
       "          [-4.0124e-02,  5.2928e-02,  1.0430e-01,  ..., -3.0259e-03,\n",
       "           -1.4651e-03, -7.3178e-02],\n",
       "          [-6.4239e-02,  2.8064e-02,  1.1533e-01,  ...,  3.1496e-02,\n",
       "            1.8027e-02, -3.4342e-02],\n",
       "          [-6.9952e-02, -3.8836e-02,  7.0325e-02,  ...,  4.1024e-02,\n",
       "            2.9703e-02,  9.6591e-03]],\n",
       "\n",
       "         [[-2.2936e-03, -1.2510e-03,  1.0583e-02,  ..., -1.8314e-02,\n",
       "           -1.0289e-02,  8.0227e-03],\n",
       "          [ 2.5977e-02,  4.4461e-02,  5.1159e-02,  ..., -3.2942e-02,\n",
       "           -4.4486e-02, -6.7867e-02],\n",
       "          [ 4.5597e-02,  1.0202e-01,  9.9022e-02,  ...,  1.2194e-02,\n",
       "           -9.5016e-03, -8.9611e-02],\n",
       "          ...,\n",
       "          [-9.6234e-05,  1.1187e-01,  1.5457e-01,  ...,  3.3808e-02,\n",
       "            7.2456e-03, -9.8750e-02],\n",
       "          [-2.3022e-02,  5.9308e-02,  1.6529e-01,  ...,  4.9100e-02,\n",
       "            1.3450e-02, -6.3435e-02],\n",
       "          [-4.4896e-02, -6.3747e-03,  9.6473e-02,  ...,  5.8484e-02,\n",
       "            1.6685e-02, -4.3562e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.3602e-02,  1.2809e-02, -8.5212e-03,  ...,  5.3807e-03,\n",
       "            2.7100e-02,  1.3490e-02],\n",
       "          [ 2.2917e-02,  3.5198e-02,  4.8035e-03,  ..., -1.1706e-03,\n",
       "            2.7753e-02, -1.6860e-03],\n",
       "          [ 2.1440e-02,  5.4008e-02, -5.2061e-03,  ...,  2.1856e-02,\n",
       "            5.1826e-02, -3.4888e-03],\n",
       "          ...,\n",
       "          [-5.5502e-03,  5.9891e-02, -1.5677e-02,  ..., -7.5576e-02,\n",
       "            2.0871e-02, -1.4295e-02],\n",
       "          [-1.1200e-02,  4.6893e-02,  3.0898e-02,  ..., -7.7027e-02,\n",
       "           -7.5859e-03, -2.3176e-02],\n",
       "          [-2.9403e-02, -2.1387e-03,  1.5621e-02,  ..., -6.4173e-02,\n",
       "           -3.3792e-02, -1.7636e-02]],\n",
       "\n",
       "         [[ 4.1234e-02, -8.6892e-03,  1.4357e-02,  ...,  4.2731e-02,\n",
       "            7.2895e-02,  7.2745e-02],\n",
       "          [ 4.2429e-02,  2.0826e-03, -1.0257e-02,  ...,  2.4713e-02,\n",
       "            6.4082e-02,  2.7103e-02],\n",
       "          [ 3.1671e-02,  1.3947e-02,  4.4156e-03,  ...,  5.2211e-02,\n",
       "            8.6870e-02,  1.7160e-02],\n",
       "          ...,\n",
       "          [-8.9760e-03,  5.9180e-03,  2.4020e-03,  ..., -1.2193e-02,\n",
       "            5.8596e-02, -1.1452e-02],\n",
       "          [-2.2753e-02, -4.2954e-03,  3.3000e-02,  ..., -1.8866e-02,\n",
       "            4.8454e-02,  1.1330e-03],\n",
       "          [-4.3251e-02, -4.7945e-02,  2.9137e-03,  ...,  1.6678e-02,\n",
       "            3.1826e-02,  1.0832e-02]],\n",
       "\n",
       "         [[-4.2824e-03, -4.6740e-02, -4.6934e-02,  ..., -5.2465e-02,\n",
       "           -5.4470e-02, -5.6484e-02],\n",
       "          [ 7.2990e-03,  8.1151e-03, -3.1316e-03,  ..., -5.6778e-02,\n",
       "           -7.3208e-02, -1.4105e-01],\n",
       "          [ 3.0420e-02,  5.6502e-02,  5.9979e-02,  ...,  6.0582e-03,\n",
       "           -1.2024e-02, -1.3908e-01],\n",
       "          ...,\n",
       "          [ 2.2103e-03,  9.0434e-02,  1.1340e-01,  ...,  2.8028e-02,\n",
       "            3.0987e-02, -9.7761e-02],\n",
       "          [-3.3107e-02,  4.7928e-02,  1.2132e-01,  ...,  4.8298e-02,\n",
       "            1.5690e-02, -8.0171e-02],\n",
       "          [-7.9640e-02, -3.3682e-02,  7.0722e-02,  ...,  4.3168e-02,\n",
       "            7.2242e-03, -7.4365e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.2656e-02, -1.3205e-02, -1.7344e-02,  ..., -1.8895e-02,\n",
       "           -7.6984e-03,  2.2585e-03],\n",
       "          [-5.5099e-03,  2.4682e-03, -1.1658e-02,  ..., -1.5429e-02,\n",
       "           -3.1265e-03,  1.0641e-02],\n",
       "          [ 2.7748e-03,  4.3607e-03, -8.8811e-03,  ..., -1.0568e-02,\n",
       "           -3.2049e-03,  2.4152e-03],\n",
       "          ...,\n",
       "          [-1.6299e-02, -2.9791e-03, -2.6608e-02,  ..., -2.2288e-02,\n",
       "           -1.3237e-02, -3.2187e-02],\n",
       "          [-6.9841e-04,  1.6186e-02, -1.8540e-03,  ...,  8.0672e-05,\n",
       "           -1.0145e-02, -6.9756e-03],\n",
       "          [ 3.8181e-03,  2.5430e-02,  9.7283e-03,  ...,  3.9845e-03,\n",
       "           -3.3272e-04, -6.8524e-03]],\n",
       "\n",
       "         [[-1.0524e-02, -1.5332e-02, -3.3691e-02,  ..., -1.9731e-02,\n",
       "           -1.1475e-02, -2.6300e-02],\n",
       "          [-1.6859e-02, -1.2487e-02, -2.4209e-02,  ..., -7.1606e-03,\n",
       "           -1.5672e-02, -3.3568e-02],\n",
       "          [-1.1889e-02, -6.0150e-03, -4.2080e-03,  ..., -3.8315e-03,\n",
       "           -1.1293e-04, -8.9605e-03],\n",
       "          ...,\n",
       "          [-2.2310e-02, -7.6311e-03, -1.0576e-02,  ..., -2.5426e-02,\n",
       "           -4.3459e-02, -4.8758e-02],\n",
       "          [-8.8625e-03, -2.1764e-03, -3.4808e-03,  ..., -4.3008e-02,\n",
       "           -3.3664e-02, -5.2355e-02],\n",
       "          [-2.0338e-02, -3.5944e-03, -6.5353e-03,  ..., -4.0623e-02,\n",
       "           -4.7648e-02, -3.7702e-02]],\n",
       "\n",
       "         [[ 1.8218e-02,  1.9164e-02,  2.0695e-02,  ...,  3.1074e-02,\n",
       "            2.1682e-02,  2.3201e-03],\n",
       "          [ 2.9656e-02,  2.8957e-02,  1.8994e-02,  ...,  4.8933e-02,\n",
       "            4.4002e-02,  2.7423e-02],\n",
       "          [ 3.1082e-02,  3.7269e-02,  3.7644e-02,  ...,  6.9215e-02,\n",
       "            5.3533e-02,  4.0646e-02],\n",
       "          ...,\n",
       "          [ 2.3680e-02,  4.9279e-02,  5.2722e-02,  ...,  6.9040e-02,\n",
       "            5.3829e-02,  3.0124e-02],\n",
       "          [ 4.6757e-02,  6.1200e-02,  4.0662e-02,  ...,  4.1352e-02,\n",
       "            3.5877e-02,  1.3257e-02],\n",
       "          [ 4.3893e-02,  6.3344e-02,  5.2536e-02,  ...,  3.6489e-02,\n",
       "            2.6490e-02,  3.3453e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.8518e-02, -6.8993e-03, -1.2433e-02,  ..., -1.9484e-02,\n",
       "            1.4553e-02,  1.5794e-02],\n",
       "          [-1.1818e-02, -2.7305e-03, -1.9076e-02,  ..., -8.9784e-03,\n",
       "            2.6024e-02,  1.9219e-02],\n",
       "          [-6.9184e-03, -1.8178e-02, -1.6475e-02,  ..., -1.7068e-03,\n",
       "            1.4836e-02,  2.8308e-02],\n",
       "          ...,\n",
       "          [ 1.2068e-02,  6.5768e-03, -2.1860e-03,  ...,  5.6713e-04,\n",
       "            1.6740e-02,  2.5866e-02],\n",
       "          [ 3.2211e-02,  3.6312e-02,  2.4687e-02,  ...,  8.9725e-03,\n",
       "            1.6450e-02,  2.2954e-02],\n",
       "          [ 3.3476e-02,  4.8888e-02,  4.4039e-02,  ...,  2.9331e-02,\n",
       "            1.9440e-02,  2.7868e-02]],\n",
       "\n",
       "         [[-3.7302e-05, -8.7115e-03, -7.4479e-03,  ...,  8.1952e-03,\n",
       "           -1.7006e-02, -2.8772e-02],\n",
       "          [-2.5678e-02, -2.3184e-02, -3.2826e-02,  ...,  1.4525e-02,\n",
       "            6.1601e-03, -1.0122e-02],\n",
       "          [ 1.6258e-03,  1.3681e-02,  3.0993e-02,  ...,  9.9700e-02,\n",
       "            6.1272e-02,  3.7307e-02],\n",
       "          ...,\n",
       "          [ 9.5834e-03,  9.5477e-02,  1.3450e-01,  ...,  1.9786e-01,\n",
       "            1.2351e-01,  6.7233e-02],\n",
       "          [-1.0504e-02,  7.4266e-02,  1.0185e-01,  ...,  1.3588e-01,\n",
       "            6.3879e-02,  1.0012e-02],\n",
       "          [-4.9865e-02,  3.8784e-02,  4.7855e-02,  ...,  8.5638e-02,\n",
       "            7.6768e-03, -3.0627e-02]],\n",
       "\n",
       "         [[ 3.5866e-02, -2.1598e-03, -3.4704e-02,  ..., -7.8277e-02,\n",
       "           -2.3594e-02,  1.0480e-02],\n",
       "          [-3.0187e-02, -7.6147e-02, -1.1001e-01,  ..., -1.4401e-01,\n",
       "           -7.7674e-02, -4.4104e-02],\n",
       "          [-6.2356e-02, -8.6674e-02, -1.0692e-01,  ..., -1.3626e-01,\n",
       "           -7.7480e-02, -5.1547e-02],\n",
       "          ...,\n",
       "          [-7.9408e-02, -6.4633e-02, -9.3645e-02,  ..., -1.2478e-01,\n",
       "           -9.4962e-02, -7.5412e-02],\n",
       "          [-5.8886e-02, -5.0502e-02, -7.0211e-02,  ..., -1.2173e-01,\n",
       "           -9.5899e-02, -7.4332e-02],\n",
       "          [-4.2395e-02, -3.3995e-02, -4.3442e-02,  ..., -9.8596e-02,\n",
       "           -7.4200e-02, -6.4506e-02]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-3.0363e-02, -7.9156e-03, -8.7859e-03,  ...,  1.1045e-02,\n",
       "            2.2490e-02,  1.6031e-02],\n",
       "          [-9.2347e-03, -6.3020e-03, -2.1268e-03,  ...,  1.6180e-02,\n",
       "            3.7987e-02,  2.9095e-02],\n",
       "          [-8.5605e-04,  8.0903e-03, -2.6024e-03,  ...,  2.9224e-02,\n",
       "            3.9405e-02,  4.5617e-02],\n",
       "          ...,\n",
       "          [ 2.4381e-02,  5.0990e-02,  5.4871e-02,  ...,  8.0021e-02,\n",
       "            8.2924e-02,  9.4455e-02],\n",
       "          [ 2.3922e-02,  4.6956e-02,  4.6338e-02,  ...,  6.9533e-02,\n",
       "            8.5884e-02,  8.2554e-02],\n",
       "          [ 1.0919e-03,  4.1322e-02,  4.1286e-02,  ...,  5.5828e-02,\n",
       "            7.0713e-02,  6.1208e-02]],\n",
       "\n",
       "         [[ 9.2092e-03, -2.3363e-03,  8.2231e-03,  ...,  3.4027e-02,\n",
       "            3.1460e-02,  3.1138e-02],\n",
       "          [ 1.1889e-02,  4.2872e-03,  1.1429e-04,  ...,  1.5958e-02,\n",
       "            2.9118e-02,  2.7763e-02],\n",
       "          [ 2.6675e-02,  2.7835e-02,  8.0723e-03,  ...,  1.5885e-02,\n",
       "            2.7583e-02,  2.9262e-02],\n",
       "          ...,\n",
       "          [ 4.7971e-02,  7.6889e-02,  4.6724e-02,  ...,  7.9891e-02,\n",
       "            9.3869e-02,  9.5065e-02],\n",
       "          [ 4.7270e-02,  6.0742e-02,  4.6198e-02,  ...,  8.8893e-02,\n",
       "            9.4137e-02,  1.0394e-01],\n",
       "          [ 2.4561e-02,  5.4478e-02,  3.7711e-02,  ...,  7.1060e-02,\n",
       "            8.5763e-02,  8.2742e-02]],\n",
       "\n",
       "         [[ 8.6718e-04, -1.5744e-02, -3.6734e-02,  ..., -3.0653e-02,\n",
       "           -1.8779e-02, -7.2986e-03],\n",
       "          [-8.6824e-03, -3.0198e-02, -4.9466e-02,  ..., -5.2367e-02,\n",
       "           -4.5012e-02, -2.4667e-02],\n",
       "          [-1.1873e-02, -2.8986e-02, -7.5367e-02,  ..., -8.4330e-02,\n",
       "           -5.7005e-02, -4.5752e-02],\n",
       "          ...,\n",
       "          [ 8.4668e-04, -2.0548e-02, -6.5449e-02,  ..., -7.6668e-02,\n",
       "           -2.8616e-02, -2.0339e-02],\n",
       "          [-3.4367e-03, -2.3085e-02, -4.5418e-02,  ..., -5.5451e-02,\n",
       "           -2.1753e-02, -8.3525e-03],\n",
       "          [-2.0015e-02, -1.7065e-02, -5.0654e-02,  ..., -5.6575e-02,\n",
       "           -2.0045e-02, -2.2478e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-7.1648e-03, -1.1642e-02, -2.0201e-02,  ..., -2.2399e-02,\n",
       "           -2.1484e-02, -1.1636e-02],\n",
       "          [-1.7318e-02, -1.0308e-02, -2.3476e-02,  ..., -3.8865e-02,\n",
       "           -2.1519e-02, -2.8335e-02],\n",
       "          [-1.6593e-02, -2.6232e-02, -2.0868e-02,  ..., -3.9070e-02,\n",
       "           -1.8373e-02, -1.8405e-02],\n",
       "          ...,\n",
       "          [-1.0133e-02, -2.5105e-02, -3.6371e-02,  ..., -3.9762e-02,\n",
       "           -3.8945e-02, -2.6552e-02],\n",
       "          [-7.5614e-03, -1.6717e-02, -2.6813e-02,  ..., -4.4005e-02,\n",
       "           -2.4510e-02, -3.9149e-02],\n",
       "          [-1.9852e-02, -2.5141e-02, -2.7087e-02,  ..., -3.2492e-02,\n",
       "           -3.2339e-02, -3.2298e-02]],\n",
       "\n",
       "         [[ 1.3171e-03,  3.9603e-03, -6.1710e-03,  ...,  5.0125e-03,\n",
       "            1.1451e-02, -1.2947e-02],\n",
       "          [-5.7288e-03, -1.2035e-02, -2.1970e-02,  ..., -1.8330e-02,\n",
       "           -5.9719e-03, -2.1313e-02],\n",
       "          [ 5.1155e-03, -9.9472e-03, -1.5924e-02,  ..., -1.7103e-02,\n",
       "           -5.2785e-03, -1.1546e-02],\n",
       "          ...,\n",
       "          [-5.8928e-04, -1.7239e-02, -2.5481e-02,  ..., -1.9489e-02,\n",
       "           -6.2162e-03, -3.4662e-03],\n",
       "          [ 7.3874e-03, -2.2639e-03, -1.5372e-02,  ..., -4.6877e-03,\n",
       "           -1.9765e-03,  4.6594e-03],\n",
       "          [ 6.8878e-03, -7.8972e-04, -2.6328e-02,  ..., -8.5284e-03,\n",
       "            3.9374e-03,  1.2443e-02]],\n",
       "\n",
       "         [[ 1.2858e-02,  3.3928e-03, -8.8427e-03,  ..., -4.7728e-03,\n",
       "           -1.1628e-02, -7.2931e-03],\n",
       "          [ 1.0117e-02,  3.9562e-03, -2.6847e-02,  ..., -1.4542e-02,\n",
       "           -2.3433e-03, -1.1086e-02],\n",
       "          [ 1.4709e-02,  9.8557e-04, -2.0562e-02,  ..., -9.1003e-03,\n",
       "            2.1151e-03,  2.5566e-03],\n",
       "          ...,\n",
       "          [ 3.8592e-02,  4.2688e-02,  1.8224e-02,  ...,  3.1772e-02,\n",
       "            4.0334e-02,  3.9210e-02],\n",
       "          [ 4.3607e-02,  3.6203e-02,  2.1275e-02,  ...,  4.7504e-02,\n",
       "            5.8669e-02,  4.8490e-02],\n",
       "          [ 2.2405e-02,  3.2626e-02,  1.9718e-02,  ...,  2.7771e-02,\n",
       "            4.9567e-02,  3.3587e-02]]],\n",
       "\n",
       "\n",
       "        [[[-2.9591e-02, -3.5788e-03,  1.8833e-02,  ..., -8.9529e-03,\n",
       "           -2.4876e-03, -8.3773e-03],\n",
       "          [ 9.4157e-03, -3.7837e-02,  3.8529e-02,  ..., -1.1331e-02,\n",
       "            2.0425e-02,  1.8713e-02],\n",
       "          [-2.7032e-02, -2.9803e-02,  1.3366e-01,  ..., -3.1880e-02,\n",
       "            5.8231e-03,  4.1360e-02],\n",
       "          ...,\n",
       "          [-5.5825e-03,  6.0704e-02,  1.4278e-01,  ..., -1.7816e-01,\n",
       "            1.5987e-02,  5.0154e-02],\n",
       "          [-6.3434e-03,  3.9143e-02,  2.7854e-02,  ..., -1.0278e-01,\n",
       "            6.2242e-02,  1.2060e-02],\n",
       "          [ 1.3481e-03,  6.3535e-03, -4.2091e-03,  ..., -2.1996e-02,\n",
       "            3.1759e-02, -2.5409e-02]],\n",
       "\n",
       "         [[ 1.0273e-01,  7.8484e-02, -1.0083e-03,  ..., -6.7696e-02,\n",
       "           -5.3897e-02, -3.8975e-02],\n",
       "          [ 1.1920e-01, -6.9895e-02, -1.0696e-01,  ..., -9.2568e-02,\n",
       "           -2.8990e-02,  3.9409e-03],\n",
       "          [ 3.1002e-03, -1.7771e-01, -9.8583e-02,  ..., -8.2457e-02,\n",
       "            1.3581e-02,  4.5927e-02],\n",
       "          ...,\n",
       "          [-3.3703e-02, -6.8194e-02,  3.9325e-02,  ..., -3.4606e-03,\n",
       "            1.7356e-01,  8.9864e-02],\n",
       "          [-3.6058e-02, -3.5080e-02,  9.8143e-04,  ...,  7.4257e-02,\n",
       "            1.5691e-01, -1.1405e-02],\n",
       "          [-8.2888e-03, -1.3163e-02,  1.1546e-02,  ...,  9.9810e-02,\n",
       "            5.0742e-02, -1.2140e-01]],\n",
       "\n",
       "         [[ 9.2689e-02,  5.8996e-02,  7.5181e-03,  ..., -2.7654e-02,\n",
       "           -1.9341e-03,  8.0232e-03],\n",
       "          [ 1.0692e-01, -7.1741e-02, -9.9663e-02,  ..., -4.8646e-02,\n",
       "            1.9911e-02,  6.0055e-02],\n",
       "          [ 6.1664e-03, -1.7520e-01, -7.4560e-02,  ..., -2.7071e-02,\n",
       "            7.0247e-02,  1.0075e-01],\n",
       "          ...,\n",
       "          [-2.3493e-02, -4.8342e-02,  7.3591e-02,  ...,  4.5824e-02,\n",
       "            2.2324e-01,  1.3858e-01],\n",
       "          [-1.4704e-02, -2.0612e-02,  4.0375e-02,  ...,  1.3053e-01,\n",
       "            2.0424e-01,  2.8346e-02],\n",
       "          [ 2.2071e-02,  9.7340e-03,  5.6422e-02,  ...,  1.3893e-01,\n",
       "            9.8019e-02, -7.2136e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.6855e-03,  4.1538e-02,  6.3726e-02,  ...,  1.3189e-02,\n",
       "           -1.0502e-02, -7.8000e-03],\n",
       "          [-5.0968e-03, -1.1778e-02,  6.1066e-02,  ...,  5.5903e-03,\n",
       "           -2.3815e-02, -1.2868e-02],\n",
       "          [-3.5540e-02, -2.8148e-02,  1.5598e-01,  ..., -3.7428e-02,\n",
       "           -4.2428e-02, -5.2531e-03],\n",
       "          ...,\n",
       "          [-1.4068e-02,  8.5087e-02,  1.8014e-01,  ..., -1.8089e-01,\n",
       "           -1.1738e-02,  2.2538e-02],\n",
       "          [-1.9418e-03,  3.7364e-02,  2.3989e-02,  ..., -1.1666e-01,\n",
       "            2.5369e-02, -2.1922e-02],\n",
       "          [ 5.5114e-03, -1.2045e-02, -3.2727e-02,  ..., -5.4863e-02,\n",
       "           -2.2061e-03, -6.8294e-02]],\n",
       "\n",
       "         [[ 2.1361e-02,  3.1115e-02,  2.0854e-02,  ...,  3.1287e-04,\n",
       "            3.0310e-03,  1.5203e-03],\n",
       "          [ 8.2543e-02, -2.4623e-02,  2.0394e-02,  ..., -2.8096e-02,\n",
       "            5.9769e-03,  1.4422e-02],\n",
       "          [ 9.6360e-03, -7.2542e-02,  6.9454e-02,  ..., -5.0431e-02,\n",
       "           -9.6831e-03,  3.1225e-02],\n",
       "          ...,\n",
       "          [ 8.9119e-03,  1.0626e-02,  1.2031e-01,  ..., -1.4489e-01,\n",
       "            3.7032e-02,  1.6406e-02],\n",
       "          [-2.0185e-02, -2.8348e-03,  2.2914e-02,  ..., -5.4015e-02,\n",
       "            5.3346e-02, -5.6260e-02],\n",
       "          [ 1.1083e-02, -1.1558e-02, -2.1605e-03,  ...,  1.1565e-02,\n",
       "            2.0644e-03, -1.1993e-01]],\n",
       "\n",
       "         [[ 4.8220e-02,  1.7099e-02, -3.1941e-02,  ..., -3.6828e-02,\n",
       "           -4.2655e-02, -1.3090e-02],\n",
       "          [ 4.2314e-02, -9.9717e-02, -7.8534e-02,  ..., -7.1492e-02,\n",
       "           -3.3452e-02,  1.8786e-02],\n",
       "          [-4.1241e-02, -1.4750e-01, -1.0183e-02,  ..., -4.5983e-02,\n",
       "            5.4683e-03,  7.5905e-02],\n",
       "          ...,\n",
       "          [-2.7656e-02,  6.2216e-03,  1.3887e-01,  ..., -1.5622e-02,\n",
       "            1.4164e-01,  1.2898e-01],\n",
       "          [-6.5229e-02, -1.9921e-02,  2.7078e-02,  ...,  3.4879e-02,\n",
       "            1.2088e-01,  4.9483e-03],\n",
       "          [-1.2262e-02, -1.2302e-02,  4.3457e-02,  ...,  1.1341e-01,\n",
       "            7.9302e-02, -7.6145e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4848e-02,  1.4787e-02,  9.1203e-03,  ...,  6.9757e-03,\n",
       "            1.8710e-02,  1.9400e-02],\n",
       "          [-1.3472e-02, -2.9671e-03,  5.3936e-03,  ...,  4.9727e-03,\n",
       "            1.0785e-03,  9.0933e-03],\n",
       "          [ 1.4751e-03,  2.3853e-02,  2.6564e-02,  ...,  9.2237e-03,\n",
       "            1.9199e-02,  1.2172e-02],\n",
       "          ...,\n",
       "          [-3.4196e-03,  1.0942e-02,  1.3172e-02,  ...,  2.2676e-02,\n",
       "            2.9263e-02,  1.1010e-02],\n",
       "          [ 5.6260e-03,  7.4419e-03,  1.9900e-02,  ...,  2.6533e-02,\n",
       "            3.4075e-02,  2.5255e-02],\n",
       "          [ 1.3797e-02,  1.9855e-02,  3.8634e-02,  ...,  2.2385e-02,\n",
       "            2.6701e-02,  3.3532e-02]],\n",
       "\n",
       "         [[-8.1019e-02, -7.7212e-02, -6.1371e-02,  ..., -4.4472e-02,\n",
       "           -4.6020e-02, -6.8235e-02],\n",
       "          [-8.5170e-02, -6.0738e-02, -5.1646e-02,  ..., -4.0298e-02,\n",
       "           -4.1718e-02, -5.6776e-02],\n",
       "          [-4.5832e-02, -1.9042e-02, -1.4644e-03,  ..., -1.9442e-02,\n",
       "           -2.2512e-02, -3.5969e-02],\n",
       "          ...,\n",
       "          [-3.1256e-02, -2.3778e-02, -1.9252e-03,  ..., -1.0943e-02,\n",
       "           -2.2939e-02, -1.9750e-02],\n",
       "          [-2.2534e-02, -2.0889e-03,  2.3791e-03,  ..., -7.1830e-03,\n",
       "           -1.9864e-03, -8.2012e-03],\n",
       "          [-3.4124e-03,  1.1145e-02,  1.9385e-02,  ...,  1.9885e-02,\n",
       "           -1.4643e-03, -5.0929e-03]],\n",
       "\n",
       "         [[-5.8108e-04,  2.1323e-02,  4.4870e-02,  ...,  4.6646e-02,\n",
       "            2.9313e-02, -1.3869e-02],\n",
       "          [ 2.9192e-02,  7.6074e-02,  7.8826e-02,  ...,  6.9358e-02,\n",
       "            3.8413e-02,  1.5616e-02],\n",
       "          [ 6.8068e-02,  1.0443e-01,  1.0083e-01,  ...,  6.1234e-02,\n",
       "            5.0559e-02,  2.8116e-02],\n",
       "          ...,\n",
       "          [ 3.8208e-02,  4.0756e-02,  2.6079e-02,  ...,  2.2937e-02,\n",
       "            1.9550e-02,  2.8556e-02],\n",
       "          [ 4.6784e-02,  4.1710e-02,  4.4588e-02,  ...,  2.9677e-02,\n",
       "            3.3419e-02,  2.7420e-02],\n",
       "          [ 5.2318e-02,  5.9438e-02,  6.8416e-02,  ...,  3.9042e-02,\n",
       "            4.2954e-02,  2.2213e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.3337e-02, -2.0861e-02, -1.8886e-02,  ..., -2.4542e-02,\n",
       "           -3.1632e-02, -1.7056e-02],\n",
       "          [-1.7079e-02, -1.9423e-02, -1.5936e-02,  ..., -3.3980e-02,\n",
       "           -3.0550e-02, -2.3302e-02],\n",
       "          [-6.9191e-03, -1.6405e-02, -1.1678e-02,  ..., -3.2362e-02,\n",
       "           -2.2226e-02, -3.5177e-02],\n",
       "          ...,\n",
       "          [-1.5703e-02, -1.3407e-02, -2.0764e-02,  ..., -1.6620e-02,\n",
       "           -2.0607e-02, -1.6091e-02],\n",
       "          [-5.8960e-03, -1.0210e-02, -5.4256e-03,  ..., -1.0163e-02,\n",
       "           -7.1679e-03, -1.2149e-02],\n",
       "          [-1.1330e-02, -9.3239e-03, -1.0925e-02,  ..., -1.8326e-02,\n",
       "           -4.4684e-03, -1.3762e-02]],\n",
       "\n",
       "         [[-2.2673e-02,  4.2832e-02,  7.1483e-02,  ...,  5.2991e-02,\n",
       "            8.5864e-02,  8.0306e-02],\n",
       "          [ 4.9373e-02,  9.5330e-02,  9.6647e-02,  ...,  1.0364e-01,\n",
       "            1.4038e-01,  1.5421e-01],\n",
       "          [ 5.5964e-02,  7.7069e-02,  7.5913e-02,  ...,  6.2523e-02,\n",
       "            1.0924e-01,  1.3602e-01],\n",
       "          ...,\n",
       "          [-1.3225e-02, -4.1133e-02, -4.7723e-02,  ..., -5.6617e-02,\n",
       "            1.3457e-02,  6.1890e-02],\n",
       "          [ 2.0304e-02, -2.3016e-02, -2.8049e-02,  ..., -3.7770e-02,\n",
       "            1.7590e-02,  5.6491e-02],\n",
       "          [ 3.3020e-02,  5.7787e-03, -1.6112e-04,  ..., -2.8092e-02,\n",
       "            1.7610e-02,  4.3566e-02]],\n",
       "\n",
       "         [[ 2.7455e-02,  4.2265e-02,  4.3028e-02,  ...,  3.7653e-02,\n",
       "            6.2558e-02,  6.9099e-02],\n",
       "          [ 4.3613e-02,  3.9342e-02,  1.4988e-02,  ...,  3.9822e-03,\n",
       "            5.3654e-02,  8.1360e-02],\n",
       "          [ 2.5127e-02, -1.0509e-02, -3.9341e-02,  ..., -4.0773e-02,\n",
       "            2.1054e-02,  6.8853e-02],\n",
       "          ...,\n",
       "          [-3.1893e-02, -1.0582e-01, -1.4018e-01,  ..., -1.3729e-01,\n",
       "           -7.5158e-02,  5.1408e-03],\n",
       "          [ 1.0848e-02, -6.4234e-02, -9.5972e-02,  ..., -1.0918e-01,\n",
       "           -3.3415e-02,  4.2725e-02],\n",
       "          [ 6.4974e-02, -1.1307e-02, -4.4841e-02,  ..., -6.7677e-02,\n",
       "           -1.2406e-02,  4.0187e-02]]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_model.encoder.conv1.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = model(train_ds[0]['image'].unsqueeze(0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ConcatDataset([train_ds, val_ds])\n",
    "train_dl = DataLoader(train_ds, batch_size=512, shuffle=True, num_workers=8)\n",
    "test_dl = DataLoader(test_ds, batch_size=512, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 19])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mehzoahis\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/haozhesi/Dropbox/GeospatialFM/wandb/run-20231008_000732-j7iyp68e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ehzoahis/huggingface/runs/j7iyp68e' target=\"_blank\">misunderstood-violet-3</a></strong> to <a href='https://wandb.ai/ehzoahis/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ehzoahis/huggingface' target=\"_blank\">https://wandb.ai/ehzoahis/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ehzoahis/huggingface/runs/j7iyp68e' target=\"_blank\">https://wandb.ai/ehzoahis/huggingface/runs/j7iyp68e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/haozhesi/Dropbox/GeospatialFM/torchgeo_playground.ipynb Cell 12\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2245756c6572227d/home/haozhesi/Dropbox/GeospatialFM/torchgeo_playground.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2245756c6572227d/home/haozhesi/Dropbox/GeospatialFM/torchgeo_playground.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,                \u001b[39m# the instantiated 🤗 Transformers model to be trained\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2245756c6572227d/home/haozhesi/Dropbox/GeospatialFM/torchgeo_playground.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,                   \u001b[39m# training arguments, defined above\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2245756c6572227d/home/haozhesi/Dropbox/GeospatialFM/torchgeo_playground.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     compute_metrics\u001b[39m=\u001b[39mcompute_metrics,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2245756c6572227d/home/haozhesi/Dropbox/GeospatialFM/torchgeo_playground.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m )\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2245756c6572227d/home/haozhesi/Dropbox/GeospatialFM/torchgeo_playground.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/anaconda3/envs/sat/lib/python3.10/site-packages/transformers/trainer.py:1553\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1554\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1555\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1556\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1557\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1558\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/sat/lib/python3.10/site-packages/transformers/trainer.py:1813\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1810\u001b[0m     rng_to_sync \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1812\u001b[0m step \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m-> 1813\u001b[0m \u001b[39mfor\u001b[39;00m step, inputs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m   1814\u001b[0m     total_batched_samples \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1815\u001b[0m     \u001b[39mif\u001b[39;00m rng_to_sync:\n",
      "File \u001b[0;32m~/anaconda3/envs/sat/lib/python3.10/site-packages/accelerate/data_loader.py:384\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[39m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 384\u001b[0m     current_batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(dataloader_iter)\n\u001b[1;32m    385\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[39myield\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sat/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/sat/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sat/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m   1283\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[0;32m-> 1284\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1285\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1286\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/sat/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1133\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sat/lib/python3.10/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[39mif\u001b[39;00m remaining \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait(remaining)\n\u001b[1;32m    181\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_full\u001b[39m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/anaconda3/envs/sat/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[1;32m    325\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                   # training arguments, defined above\n",
    "    train_dataset=train_ds,    # training dataset\n",
    "    eval_dataset=test_ds,      # evaluation dataset\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(model, dataloader, device):\n",
    "    x_all = []\n",
    "    y_all = []\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "        images = batch[\"image\"].to(device)\n",
    "        labels = batch[\"label\"].numpy()\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            features = model(images).cpu().numpy()\n",
    "        \n",
    "        x_all.append(features)\n",
    "        y_all.append(labels)\n",
    "\n",
    "    x_all = np.concatenate(x_all, axis=0)\n",
    "    y_all = np.concatenate(y_all, axis=0)\n",
    "\n",
    "    return x_all, y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:22<00:00,  1.92s/it]\n"
     ]
    }
   ],
   "source": [
    "x_all, y_all = extract_features(model.base_model, train_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:30<00:00,  2.75s/it]\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test = extract_features(model.base_model, test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haozhesi/anaconda3/envs/sat/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=50.0, max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=50.0, max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=50.0, max_iter=1000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = LogisticRegression(C=50.0, max_iter=1000)\n",
    "linear_model.fit(x_all, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9377777777777778"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'architecture': 'vit_small_patch16_224', 'bands': 13, 'num_classes': 10, 'pretrained_ckpt': 'ViTSmall16_Weights.SENTINEL2_ALL_DINO', 'lp': False, 'head_extra_kwargs': {'use_bias': True}, 'load_pretrained_from': 'torchgeo'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cfg = cfg['MODEL']\n",
    "model_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = construct_model(model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (base_model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(13, 384, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (task_head): ClassificationHead(in_features=384, out_features=10, bias=True)\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tgm.get_weight(model_cfg['pretrained_ckpt'])\n",
    "encoder = tgm.get_model(model_cfg['architecture'], weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.head.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haozhesi/anaconda3/envs/sat/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# get the last layer of the encoder\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vit_base_patch14_dinov2',\n",
       " 'vit_giant_patch14_dinov2',\n",
       " 'vit_large_patch14_dinov2',\n",
       " 'vit_small_patch14_dinov2']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models('*dino*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "224/14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
