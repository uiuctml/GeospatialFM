{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haozhesi/anaconda3/envs/sat/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "\n",
    "from GeospatialFM.data import get_datasets\n",
    "from GeospatialFM.models import *\n",
    "# from utils import load_config\n",
    "from torchgeo.samplers import RandomGeoSampler\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from GeospatialFM.utils import setup, get_eval_fn, get_data, init_distributed_device\n",
    "from GeospatialFM.data import *\n",
    "from GeospatialFM.models import *\n",
    "from GeospatialFM.loss import *\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.data import ConcatDataset\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(exp_name=None, config_file='GeospatialFM/configs/pretrain_cvit.yaml', opts=None, save_config=False, debug=True, finetune=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = {'exp_name': None,\n",
    "        'config_file': 'GeospatialFM/configs/pretrain_cvit.yaml',\n",
    "        'opts': None, \n",
    "        'save_config': False}\n",
    "args = argparse.Namespace(**args)\n",
    "args.debug = True\n",
    "args.finetune = False\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Namespace' object has no attribute 'rank'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cfg, _ \u001b[38;5;241m=\u001b[39m \u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dropbox/GeospatialFM/GeospatialFM/utils/configs.py:57\u001b[0m, in \u001b[0;36msetup\u001b[0;34m(args, wandb)\u001b[0m\n\u001b[1;32m     55\u001b[0m cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRAINER\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_dir\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATASET\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNAME\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     56\u001b[0m cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRAINER\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogging_dir\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATASET\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNAME\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_master\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     58\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRAINER\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_dir\u001b[39m\u001b[38;5;124m'\u001b[39m], exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     59\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRAINER\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogging_dir\u001b[39m\u001b[38;5;124m'\u001b[39m], exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Dropbox/GeospatialFM/GeospatialFM/utils/distributed.py:16\u001b[0m, in \u001b[0;36mis_master\u001b[0;34m(args, local)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_master\u001b[39m(args, local\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m is_local_master(args) \u001b[38;5;28;01mif\u001b[39;00m local \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mis_global_master\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dropbox/GeospatialFM/GeospatialFM/utils/distributed.py:8\u001b[0m, in \u001b[0;36mis_global_master\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_global_master\u001b[39m(args):\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrank\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Namespace' object has no attribute 'rank'"
     ]
    }
   ],
   "source": [
    "device = init_distributed_device(args)\n",
    "cfg, _ = setup(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.DATASET['train_transforms']['normalize'] = True\n",
    "cfg.DATASET['train_transforms']['standardize'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(cfg)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = iter(data['test'].dataloader).__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = construct_mae(cfg.MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "device_ids = [0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "model = torch.nn.DataParallel(model, device_ids=device_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = get_loss_list(cfg.LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = sample['image'].to(device, non_blocking=True)\n",
    "# radar = sample['radar'].to(device, non_blocking=True)\n",
    "image = sample['image']\n",
    "radar = sample['radar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_out = model(image, radar)\n",
    "# logit_scale = model_out.get(\"logit_scale\").mean()\n",
    "# model_out['logit_scale'] = logit_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points = [[20, 193], [35, 180], [55, 150], [130, 180], [95, 140], [30, 25], [80, 30]]\n",
    "points = [[45, 10], [45, 20]]\n",
    "cross_length = 5\n",
    "img_id = 100\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "color = ['r', 'g', 'b', 'cyan', 'orange', 'purple', 'brown']\n",
    "for c, point in enumerate(points):\n",
    "    curve = image[img_id, :, point[0], point[1]].detach().cpu().numpy()\n",
    "    curve = np.delete(curve, 10)\n",
    "    plt.plot(np.arange(12), curve, color[c])\n",
    "vis_img = image[img_id, [3, 2, 1], :, :].detach().cpu().numpy().transpose(1, 2, 0)\n",
    "# normalize each channel\n",
    "vis_img = (vis_img - vis_img.min()) / (vis_img.max() - vis_img.min())\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(vis_img)\n",
    "# draw a cross at the point\n",
    "for c, point in enumerate(points):\n",
    "    plt.plot([point[1] - cross_length, point[1] + cross_length], [point[0], point[0]],  color[c]) \n",
    "    # Draw vertical line of the cross\n",
    "    plt.plot([point[1], point[1]], [point[0] - cross_length, point[0] + cross_length],  color[c]) \n",
    "# plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points = [[20, 193], [35, 180], [55, 150], [130, 180], [95, 140], [30, 25], [80, 30]]\n",
    "points = [[45, 10], [45, 20]]\n",
    "cross_length = 5\n",
    "img_id = 150\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "color = ['r', 'g', 'b', 'cyan', 'orange', 'purple', 'brown']\n",
    "for c, point in enumerate(points):\n",
    "    curve = radar[img_id, :, point[0], point[1]].detach().cpu().numpy()\n",
    "    # curve = np.delete(curve, 10)\n",
    "    plt.plot(np.arange(2), curve, color[c])\n",
    "vis_img = radar[img_id, [0], :, :].detach().cpu().numpy().transpose(1, 2, 0)\n",
    "# normalize each channel\n",
    "vis_img = (vis_img - vis_img.min()) / (vis_img.max() - vis_img.min())\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(vis_img)\n",
    "# draw a cross at the point\n",
    "for c, point in enumerate(points):\n",
    "    plt.plot([point[1] - cross_length, point[1] + cross_length], [point[0], point[0]],  color[c]) \n",
    "    # Draw vertical line of the cross\n",
    "    plt.plot([point[1], point[1]], [point[0] - cross_length, point[0] + cross_length],  color[c]) \n",
    "# plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haozhesi/anaconda3/envs/sat/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from GeospatialFM.models.costum_layers import *\n",
    "import torch\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.randn(2, 13, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_embedding = PatchEmbedPerChannel(in_chans=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tokens = dict()\n",
    "extra_tokens[\"channels\"] = torch.tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]])\n",
    "out = patch_embedding(sample, extra_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collpase_channels(out[0], 'mean').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 13])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.25"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13*0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sample\n",
    "B, Cin, H, W = x.shape\n",
    "# Note: The current number of channels (Cin) can be smaller or equal to in_chans\n",
    "len_keep = int(Cin * 0.4)\n",
    "\n",
    "noise = torch.rand(B, Cin, device=x.device)  # noise in [0, 1]\n",
    "# sort noise for each sample\n",
    "ids_shuffle = torch.argsort(noise, dim=1)  # ascend: small is keep, large is remove\n",
    "ids_restore = torch.argsort(ids_shuffle, dim=1)\n",
    "\n",
    "# keep the first subset\n",
    "ids_keep = ids_shuffle[:, :len_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5,  5,  5,  ...,  5,  5,  5],\n",
       "          [ 5,  5,  5,  ...,  5,  5,  5],\n",
       "          [ 5,  5,  5,  ...,  5,  5,  5],\n",
       "          ...,\n",
       "          [ 5,  5,  5,  ...,  5,  5,  5],\n",
       "          [ 5,  5,  5,  ...,  5,  5,  5],\n",
       "          [ 5,  5,  5,  ...,  5,  5,  5]],\n",
       "\n",
       "         [[ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          ...,\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1]],\n",
       "\n",
       "         [[ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          ...,\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          ...,\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6]],\n",
       "\n",
       "         [[12, 12, 12,  ..., 12, 12, 12],\n",
       "          [12, 12, 12,  ..., 12, 12, 12],\n",
       "          [12, 12, 12,  ..., 12, 12, 12],\n",
       "          ...,\n",
       "          [12, 12, 12,  ..., 12, 12, 12],\n",
       "          [12, 12, 12,  ..., 12, 12, 12],\n",
       "          [12, 12, 12,  ..., 12, 12, 12]],\n",
       "\n",
       "         [[ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          ...,\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0]]],\n",
       "\n",
       "\n",
       "        [[[ 2,  2,  2,  ...,  2,  2,  2],\n",
       "          [ 2,  2,  2,  ...,  2,  2,  2],\n",
       "          [ 2,  2,  2,  ...,  2,  2,  2],\n",
       "          ...,\n",
       "          [ 2,  2,  2,  ...,  2,  2,  2],\n",
       "          [ 2,  2,  2,  ...,  2,  2,  2],\n",
       "          [ 2,  2,  2,  ...,  2,  2,  2]],\n",
       "\n",
       "         [[11, 11, 11,  ..., 11, 11, 11],\n",
       "          [11, 11, 11,  ..., 11, 11, 11],\n",
       "          [11, 11, 11,  ..., 11, 11, 11],\n",
       "          ...,\n",
       "          [11, 11, 11,  ..., 11, 11, 11],\n",
       "          [11, 11, 11,  ..., 11, 11, 11],\n",
       "          [11, 11, 11,  ..., 11, 11, 11]],\n",
       "\n",
       "         [[ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          ...,\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          ...,\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1]],\n",
       "\n",
       "         [[12, 12, 12,  ..., 12, 12, 12],\n",
       "          [12, 12, 12,  ..., 12, 12, 12],\n",
       "          [12, 12, 12,  ..., 12, 12, 12],\n",
       "          ...,\n",
       "          [12, 12, 12,  ..., 12, 12, 12],\n",
       "          [12, 12, 12,  ..., 12, 12, 12],\n",
       "          [12, 12, 12,  ..., 12, 12, 12]],\n",
       "\n",
       "         [[ 8,  8,  8,  ...,  8,  8,  8],\n",
       "          [ 8,  8,  8,  ...,  8,  8,  8],\n",
       "          [ 8,  8,  8,  ...,  8,  8,  8],\n",
       "          ...,\n",
       "          [ 8,  8,  8,  ...,  8,  8,  8],\n",
       "          [ 8,  8,  8,  ...,  8,  8,  8],\n",
       "          [ 8,  8,  8,  ...,  8,  8,  8]]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_keep.unsqueeze(-1).unsqueeze(-1).repeat(1, 5, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_keep.shape\n",
    "# sample corresponding channels from ce\n",
    "new_ce = torch.gather(ce, 2, ids_keep.unsqueeze(1).repeat(1, ce.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0149,  0.0129,  0.0069, -0.0358,  0.0500],\n",
       "        grad_fn=<SelectBackward0>),\n",
       " tensor(2),\n",
       " tensor([ 0.0149,  0.0129,  0.0069, -0.0358,  0.0500],\n",
       "        grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ce[0, :5, 0], ids_keep[0, 0], ce[0, :5, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ce[0, :5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce[0, :5, 2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather the C dim of the batch of the images in shape B x C x H x W following the index of ids_keep\n",
    "x_keep = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).unsqueeze(-1).repeat(1, 1, *x.shape[-2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 224, 224])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_keep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the binary mask: 0 is keep, 1 is remove\n",
    "mask = torch.ones([B, Cin], device=x.device)\n",
    "mask[:, :len_keep] = 0\n",
    "# unshuffle to get the binary mask\n",
    "mask = torch.gather(mask, dim=1, index=ids_restore)\n",
    "# Per batch channel sampling\n",
    "        # Note this may be slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  1,  6, 12,  0],\n",
       "        [ 2, 11,  1, 12,  8]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = torch.rand((2, 3, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_chans = 13\n",
    "embed_dim = 768\n",
    "patch_size = 16\n",
    "sample = torch.randn(320, 13, 224, 224)\n",
    "proj = nn.Conv2d(\n",
    "    in_chans,\n",
    "    embed_dim*in_chans,\n",
    "    kernel_size=(patch_size, patch_size),\n",
    "    stride=(patch_size, patch_size),\n",
    "    groups=in_chans,\n",
    ")  # CHANGED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj2 = nn.Conv2d(\n",
    "    in_chans,\n",
    "    embed_dim,\n",
    "    kernel_size=(patch_size, patch_size),\n",
    "    stride=(patch_size, patch_size),\n",
    "    bias=False\n",
    ")  # CHANGED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj3 = nn.Conv3d(\n",
    "    1,\n",
    "    embed_dim*in_chans,\n",
    "    kernel_size=(1, patch_size, patch_size),\n",
    "    stride=(1, patch_size, patch_size),\n",
    "    bias=False\n",
    ")  # CHANGED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[[ 0.0249,  0.0120, -0.0572,  ..., -0.0511,  0.0248, -0.0440],\n",
       "           [-0.0441, -0.0587, -0.0619,  ..., -0.0135, -0.0402, -0.0045],\n",
       "           [ 0.0261, -0.0029, -0.0119,  ..., -0.0543, -0.0530,  0.0458],\n",
       "           ...,\n",
       "           [ 0.0007, -0.0545, -0.0185,  ..., -0.0523, -0.0208,  0.0074],\n",
       "           [-0.0507, -0.0495,  0.0356,  ..., -0.0488, -0.0101, -0.0257],\n",
       "           [ 0.0596, -0.0471, -0.0401,  ...,  0.0415,  0.0226,  0.0603]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0493, -0.0200, -0.0521,  ...,  0.0328, -0.0307,  0.0097],\n",
       "           [-0.0096, -0.0445,  0.0035,  ..., -0.0113, -0.0321, -0.0437],\n",
       "           [-0.0133, -0.0105,  0.0075,  ...,  0.0067, -0.0246, -0.0270],\n",
       "           ...,\n",
       "           [-0.0479, -0.0200, -0.0334,  ...,  0.0114,  0.0499,  0.0596],\n",
       "           [ 0.0273,  0.0388, -0.0519,  ...,  0.0378,  0.0034,  0.0187],\n",
       "           [-0.0167, -0.0244,  0.0042,  ...,  0.0125,  0.0044,  0.0012]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0190, -0.0377, -0.0300,  ...,  0.0076,  0.0192,  0.0153],\n",
       "           [ 0.0006,  0.0523,  0.0017,  ...,  0.0341,  0.0295, -0.0044],\n",
       "           [ 0.0135,  0.0104,  0.0146,  ...,  0.0623, -0.0394, -0.0594],\n",
       "           ...,\n",
       "           [-0.0257, -0.0014,  0.0428,  ..., -0.0523, -0.0319,  0.0397],\n",
       "           [ 0.0167,  0.0474, -0.0299,  ...,  0.0205,  0.0192, -0.0139],\n",
       "           [ 0.0529,  0.0527,  0.0204,  ...,  0.0502, -0.0583,  0.0386]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0414,  0.0211,  0.0016,  ...,  0.0242, -0.0557, -0.0081],\n",
       "           [-0.0364, -0.0037, -0.0327,  ..., -0.0406, -0.0269,  0.0089],\n",
       "           [-0.0351,  0.0272,  0.0143,  ..., -0.0372,  0.0245,  0.0407],\n",
       "           ...,\n",
       "           [ 0.0299, -0.0577, -0.0587,  ...,  0.0051, -0.0268,  0.0431],\n",
       "           [-0.0136, -0.0158, -0.0036,  ...,  0.0531, -0.0295,  0.0420],\n",
       "           [ 0.0029,  0.0109,  0.0147,  ..., -0.0144, -0.0218,  0.0039]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0521, -0.0253,  0.0594,  ..., -0.0462, -0.0339,  0.0313],\n",
       "           [-0.0423, -0.0585,  0.0128,  ...,  0.0398, -0.0314,  0.0196],\n",
       "           [-0.0485,  0.0364, -0.0361,  ..., -0.0281, -0.0498,  0.0209],\n",
       "           ...,\n",
       "           [ 0.0424,  0.0423, -0.0616,  ..., -0.0609, -0.0212, -0.0575],\n",
       "           [ 0.0419,  0.0557, -0.0066,  ...,  0.0483, -0.0260, -0.0203],\n",
       "           [-0.0427, -0.0492, -0.0394,  ..., -0.0217, -0.0163, -0.0304]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0500,  0.0250, -0.0373,  ..., -0.0117, -0.0281,  0.0104],\n",
       "           [-0.0191,  0.0423,  0.0195,  ..., -0.0229,  0.0376, -0.0177],\n",
       "           [-0.0432, -0.0448, -0.0285,  ...,  0.0007, -0.0541, -0.0051],\n",
       "           ...,\n",
       "           [-0.0238,  0.0285, -0.0275,  ...,  0.0217, -0.0613, -0.0059],\n",
       "           [-0.0405,  0.0098, -0.0089,  ...,  0.0205, -0.0313,  0.0125],\n",
       "           [-0.0116,  0.0595, -0.0420,  ...,  0.0087, -0.0369,  0.0195]]]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0494, -0.0122,  0.0355,  ..., -0.0200,  0.0594,  0.0272],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p for p in proj.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2555904, 768]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.numel() for p in proj2.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9984, 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the number of parameters\n",
    "w1 = sum(p.numel() for p in proj.parameters())\n",
    "w2 = sum(p.numel() for p in proj2.parameters())\n",
    "w3 = sum(p.numel() for p in proj3.parameters())\n",
    "w1-w2, w3-w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, -2359296)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = proj.weight.flatten().shape[0]\n",
    "w2 = proj2.weight.flatten().shape[0]\n",
    "w3 = proj3.weight.flatten().shape[0]\n",
    "w1-w2, w3-w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, -2359296)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1 = proj.bias.flatten().shape[0]\n",
    "b2 = proj2.bias.flatten().shape[0]\n",
    "b3 = proj3.bias.flatten().shape[0]\n",
    "w1-w2, w3-w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj.to('cuda:1')\n",
    "proj2.to('cuda:1')\n",
    "proj3.to('cuda:1')\n",
    "sample = sample.to('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.902925729751587\n",
      "0.1449604034423828\n",
      "1.4818251132965088\n"
     ]
    }
   ],
   "source": [
    "# estimate the timw of the forward pass\n",
    "import time\n",
    "start = time.time()\n",
    "out1 = proj(sample).cpu()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "start = time.time()\n",
    "out2 = proj2(sample).cpu()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "start = time.time()     \n",
    "out3 = proj3(sample.unsqueeze(1)).cpu()\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([320, 3, 224, 224])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[:, torch.tensor([0, 1, 11])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([320, 9984, 14, 14])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([320, 768, 13, 14, 14])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40318025746819064"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5470134688105862"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.uniform(0.25, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.randn(2, 1, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = nn.Conv3d(\n",
    "    1,\n",
    "    1024,\n",
    "    kernel_size=(1, 4, 4),\n",
    "    stride=(1, 4, 4),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj2 = nn.Conv3d(\n",
    "    1024,\n",
    "    768, \n",
    "    kernel_size=(1, 4, 4),\n",
    "    stride=(1, 4, 4),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj3 = nn.Conv3d(\n",
    "    768,\n",
    "    768, \n",
    "    kernel_size=(1, 1, 1),\n",
    "    stride=(1, 1, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768, 1, 14, 14])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj3(proj2(proj(sample.unsqueeze(1)))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1180416"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_dim = 768\n",
    "proj = nn.Conv3d(\n",
    "        embed_dim*2,\n",
    "        embed_dim,\n",
    "        kernel_size=(1, 1, 1),\n",
    "        stride=(1, 1, 1),\n",
    "    )\n",
    "w = sum(p.numel() for p in proj.parameters())\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1179648"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*embed_dim**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = 'results/cache/BigEarthNet_vit_base_patch16_224_mae_base_finetune_OPTICAL/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(cache_path, split):\n",
    "    # list all files in cache_path containing split\n",
    "    cache_files = [f for f in os.listdir(cache_path) if split in f and f.endswith('.pkl')]\n",
    "    cache_files.sort()\n",
    "    features = dict(label=[], img_feature=[])\n",
    "    for f_name in cache_files:\n",
    "        print(f_name)\n",
    "        with open(os.path.join(cache_path, f_name), 'rb') as f:\n",
    "            chunk_features = pickle.load(f)\n",
    "            print(chunk_features)\n",
    "            features['label'].append(chunk_features['label'])\n",
    "            features['img_feature'].append(chunk_features['img_feature'])\n",
    "    print(features['label'])\n",
    "    features['label'] = torch.cat(features['label'], dim=0)\n",
    "    features['img_feature'] = torch.cat(features['img_feature'], dim=0)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_0.pkl\n",
      "{'label': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'img_feature': tensor([[-3.1885e-01,  1.6117e+00,  2.1697e-01,  ...,  3.7698e-02,\n",
      "         -4.4898e-01, -1.7372e-01],\n",
      "        [-7.7706e-01,  1.5149e+00,  2.2011e-01,  ...,  6.7384e-02,\n",
      "         -7.6155e-01, -3.2737e-01],\n",
      "        [-5.1657e-01,  1.5541e+00,  1.7843e-01,  ...,  4.7636e-04,\n",
      "         -5.6955e-01, -1.8474e-01],\n",
      "        ...,\n",
      "        [ 1.1849e+00,  7.6028e-02,  2.8320e-01,  ..., -1.3394e+00,\n",
      "          4.9319e-01, -5.1993e-01],\n",
      "        [ 9.4090e-01,  7.7789e-02, -1.1849e-01,  ..., -1.3606e+00,\n",
      "          1.1600e+00,  7.6003e-02],\n",
      "        [ 9.3445e-01,  1.0632e-01,  2.5254e-01,  ..., -1.5855e+00,\n",
      "          4.0105e-01, -3.8780e-02]])}\n",
      "test_1.pkl\n",
      "{'label': tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]]), 'img_feature': tensor([[ 0.7550,  0.7672,  0.5092,  ..., -1.3091,  0.5489,  0.1823],\n",
      "        [ 0.9895,  0.1519, -0.1785,  ..., -1.2555,  0.6785, -0.2748],\n",
      "        [ 0.7801,  0.4089,  0.2264,  ..., -1.6686,  0.4791, -0.3395],\n",
      "        ...,\n",
      "        [-0.3154,  0.7449,  0.3044,  ...,  0.6165,  1.2263, -1.1697],\n",
      "        [ 0.1556, -0.0948, -0.0069,  ..., -0.0425,  1.6132, -1.0756],\n",
      "        [-0.2787,  0.6068,  0.3845,  ...,  0.4891,  1.2935, -1.2406]])}\n",
      "test_2.pkl\n",
      "{'label': tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.]]), 'img_feature': tensor([[-0.3400,  0.7664,  0.3031,  ...,  0.5989,  1.3456, -1.2256],\n",
      "        [-0.2170,  0.7132,  0.3444,  ...,  0.6913,  1.3006, -1.2437],\n",
      "        [-0.2936,  0.7031,  0.3415,  ...,  0.5872,  1.2648, -1.2595],\n",
      "        ...,\n",
      "        [ 0.6251,  0.3565, -0.3340,  ...,  0.1496,  0.2131, -0.1576],\n",
      "        [ 0.1493,  0.7432, -0.2801,  ...,  0.0854,  0.4108,  0.6220],\n",
      "        [ 0.2667,  0.7083,  0.1320,  ...,  0.0140,  0.0283,  0.1678]])}\n",
      "test_3.pkl\n",
      "{'label': tensor([[1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'img_feature': tensor([[-0.0832,  0.3438,  0.4416,  ..., -0.0510,  0.8109,  0.3373],\n",
      "        [ 0.0606,  1.2993,  0.5228,  ..., -0.0355,  0.7659,  0.1778],\n",
      "        [ 0.0417,  1.2842,  0.2623,  ...,  0.0761,  0.0998, -0.1766],\n",
      "        ...,\n",
      "        [ 0.6454,  0.1857,  1.4478,  ..., -1.3535,  0.2130, -0.6174],\n",
      "        [-0.1329, -0.2694,  1.3433,  ..., -0.8576,  1.3469, -0.6509],\n",
      "        [ 0.1434, -0.2332,  1.4164,  ..., -0.7383,  0.7362, -0.5759]])}\n",
      "test_4.pkl\n",
      "{'label': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.]]), 'img_feature': tensor([[ 0.2814, -0.5790,  1.3124,  ..., -0.6784,  1.0796, -0.8199],\n",
      "        [ 0.1910,  0.1426,  1.5006,  ..., -1.0619,  0.8688, -0.7136],\n",
      "        [ 0.2011, -0.1573,  1.3760,  ..., -0.9898,  0.8871, -0.5575],\n",
      "        ...,\n",
      "        [-0.3726,  0.9232, -0.0696,  ...,  0.2753,  0.1797,  0.3100],\n",
      "        [-0.0529,  1.5398,  0.7868,  ..., -0.7176,  0.2441, -0.2289],\n",
      "        [-0.3298,  1.4326,  0.8658,  ..., -0.4598, -0.0191, -0.2530]])}\n",
      "test_5.pkl\n",
      "{'label': tensor([[0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'img_feature': tensor([[-0.6254,  1.1686,  0.6787,  ..., -0.4721, -0.0472, -0.2991],\n",
      "        [-0.8949,  1.1085,  0.1905,  ..., -0.3687,  0.3109, -0.0147],\n",
      "        [-0.9634,  0.7860,  0.0360,  ..., -0.1083,  0.0759, -0.0954],\n",
      "        ...,\n",
      "        [-0.5396, -0.7285, -0.9779,  ..., -0.4205,  0.8547,  0.1137],\n",
      "        [-0.4802, -0.7731, -1.0503,  ..., -0.2736,  1.1364,  0.5426],\n",
      "        [-0.8304, -1.0588, -1.1423,  ..., -0.3271,  0.9501,  0.2309]])}\n",
      "test_6.pkl\n",
      "test\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mload_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m, in \u001b[0;36mload_features\u001b[0;34m(cache_path, split)\u001b[0m\n\u001b[1;32m      9\u001b[0m         chunk_features \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28mprint\u001b[39m(chunk_features)\n\u001b[0;32m---> 11\u001b[0m         features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[43mchunk_features\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     12\u001b[0m         features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_feature\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(chunk_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_feature\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "load_features(cache_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelINN(nn.Module):\n",
    "    def __init__(self, n_nodes, out_channels, kernel_size, stride, padding=0):\n",
    "        super(ChannelINN, self).__init__()\n",
    "        self.conv = nn.Conv3d(1, n_nodes*out_channels, kernel_size, stride, padding)\n",
    "        self.n_nodes = n_nodes\n",
    "        self.out_channels = out_channels\n",
    "        self._x = torch.linspace(0, 1, n_nodes)\n",
    "    \n",
    "    # def _interpolate(self, x, idx):\n",
    "    def _intergral(self, x, idx):\n",
    "        pass\n",
    "        # x in shape B x n_nodes x C_out x H x W\n",
    "        \n",
    " \n",
    "    def forward(self, x, x_idx):\n",
    "        # x in shape B x 1 x C x H x W\n",
    "        assert x_idx.shape[0] == x.shape[2]\n",
    "        x = self.conv(x) # B x n_nodes*out_channels C x H x W\n",
    "        B, _, C, H, W = x.shape\n",
    "        x = x.view(B, self.n_nodes, self.out_channels, C, H, W)\n",
    "        x_ = torch.zeros(B, self.out_channels, C, H, W, device=x.device)\n",
    "        for i in range(C):\n",
    "            idx = x_idx[i]\n",
    "            fx = x[:, :, :, i, :, :]\n",
    "            x_[:, :, i, :, :] = self._interpolate(fx, idx)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChannelINN(20, 768, (1, 16, 16), (1, 16, 16))\n",
    "sample = torch.randn(2, 13, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 20, 768, 14, 14])\n",
      "torch.Size([2, 20, 768, 14, 14])\n",
      "torch.Size([2, 20, 768, 14, 14])\n",
      "torch.Size([2, 20, 768, 14, 14])\n",
      "torch.Size([2, 20, 768, 14, 14])\n",
      "torch.Size([2, 20, 768, 14, 14])\n",
      "torch.Size([2, 20, 768, 14, 14])\n",
      "torch.Size([2, 20, 768, 14, 14])\n",
      "torch.Size([2, 20, 768, 14, 14])\n",
      "torch.Size([2, 20, 768, 14, 14])\n",
      "torch.Size([2, 20, 768, 14, 14])\n",
      "torch.Size([2, 20, 768, 14, 14])\n",
      "torch.Size([2, 20, 768, 14, 14])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 20, 768, 13, 14, 14])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(sample.unsqueeze(1), torch.arange(13)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
