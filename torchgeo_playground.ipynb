{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haozhesi/anaconda3/envs/sat/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "\n",
    "from GeospatialFM.data import get_datasets\n",
    "from GeospatialFM.models import *\n",
    "# from utils import load_config\n",
    "from torchgeo.samplers import RandomGeoSampler\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from GeospatialFM.utils import setup, get_eval_fn, get_data, init_distributed_device\n",
    "from GeospatialFM.data import *\n",
    "from GeospatialFM.models import *\n",
    "from GeospatialFM.loss import *\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.data import ConcatDataset\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(exp_name=None, config_file='GeospatialFM/configs/pretrain_cvit.yaml', opts=None, save_config=False, debug=True, finetune=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = {'exp_name': None,\n",
    "        'config_file': 'GeospatialFM/configs/pretrain_cvit.yaml',\n",
    "        'opts': None, \n",
    "        'save_config': False}\n",
    "args = argparse.Namespace(**args)\n",
    "args.debug = True\n",
    "args.finetune = False\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Namespace' object has no attribute 'rank'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cfg, _ \u001b[38;5;241m=\u001b[39m \u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dropbox/GeospatialFM/GeospatialFM/utils/configs.py:57\u001b[0m, in \u001b[0;36msetup\u001b[0;34m(args, wandb)\u001b[0m\n\u001b[1;32m     55\u001b[0m cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRAINER\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_dir\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATASET\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNAME\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     56\u001b[0m cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRAINER\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogging_dir\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATASET\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNAME\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_master\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     58\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRAINER\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_dir\u001b[39m\u001b[38;5;124m'\u001b[39m], exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     59\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRAINER\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogging_dir\u001b[39m\u001b[38;5;124m'\u001b[39m], exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Dropbox/GeospatialFM/GeospatialFM/utils/distributed.py:16\u001b[0m, in \u001b[0;36mis_master\u001b[0;34m(args, local)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_master\u001b[39m(args, local\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m is_local_master(args) \u001b[38;5;28;01mif\u001b[39;00m local \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mis_global_master\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dropbox/GeospatialFM/GeospatialFM/utils/distributed.py:8\u001b[0m, in \u001b[0;36mis_global_master\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_global_master\u001b[39m(args):\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrank\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Namespace' object has no attribute 'rank'"
     ]
    }
   ],
   "source": [
    "device = init_distributed_device(args)\n",
    "cfg, _ = setup(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.DATASET['train_transforms']['normalize'] = True\n",
    "cfg.DATASET['train_transforms']['standardize'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(cfg)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = iter(data['test'].dataloader).__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = construct_mae(cfg.MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "device_ids = [0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "model = torch.nn.DataParallel(model, device_ids=device_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = get_loss_list(cfg.LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = sample['image'].to(device, non_blocking=True)\n",
    "# radar = sample['radar'].to(device, non_blocking=True)\n",
    "image = sample['image']\n",
    "radar = sample['radar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_out = model(image, radar)\n",
    "# logit_scale = model_out.get(\"logit_scale\").mean()\n",
    "# model_out['logit_scale'] = logit_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points = [[20, 193], [35, 180], [55, 150], [130, 180], [95, 140], [30, 25], [80, 30]]\n",
    "points = [[45, 10], [45, 20]]\n",
    "cross_length = 5\n",
    "img_id = 100\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "color = ['r', 'g', 'b', 'cyan', 'orange', 'purple', 'brown']\n",
    "for c, point in enumerate(points):\n",
    "    curve = image[img_id, :, point[0], point[1]].detach().cpu().numpy()\n",
    "    curve = np.delete(curve, 10)\n",
    "    plt.plot(np.arange(12), curve, color[c])\n",
    "vis_img = image[img_id, [3, 2, 1], :, :].detach().cpu().numpy().transpose(1, 2, 0)\n",
    "# normalize each channel\n",
    "vis_img = (vis_img - vis_img.min()) / (vis_img.max() - vis_img.min())\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(vis_img)\n",
    "# draw a cross at the point\n",
    "for c, point in enumerate(points):\n",
    "    plt.plot([point[1] - cross_length, point[1] + cross_length], [point[0], point[0]],  color[c]) \n",
    "    # Draw vertical line of the cross\n",
    "    plt.plot([point[1], point[1]], [point[0] - cross_length, point[0] + cross_length],  color[c]) \n",
    "# plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points = [[20, 193], [35, 180], [55, 150], [130, 180], [95, 140], [30, 25], [80, 30]]\n",
    "points = [[45, 10], [45, 20]]\n",
    "cross_length = 5\n",
    "img_id = 150\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "color = ['r', 'g', 'b', 'cyan', 'orange', 'purple', 'brown']\n",
    "for c, point in enumerate(points):\n",
    "    curve = radar[img_id, :, point[0], point[1]].detach().cpu().numpy()\n",
    "    # curve = np.delete(curve, 10)\n",
    "    plt.plot(np.arange(2), curve, color[c])\n",
    "vis_img = radar[img_id, [0], :, :].detach().cpu().numpy().transpose(1, 2, 0)\n",
    "# normalize each channel\n",
    "vis_img = (vis_img - vis_img.min()) / (vis_img.max() - vis_img.min())\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(vis_img)\n",
    "# draw a cross at the point\n",
    "for c, point in enumerate(points):\n",
    "    plt.plot([point[1] - cross_length, point[1] + cross_length], [point[0], point[0]],  color[c]) \n",
    "    # Draw vertical line of the cross\n",
    "    plt.plot([point[1], point[1]], [point[0] - cross_length, point[0] + cross_length],  color[c]) \n",
    "# plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haozhesi/anaconda3/envs/sat/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from GeospatialFM.models.costum_layers import *\n",
    "import torch\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.randn(2, 13, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_embedding = PatchEmbedPerChannel(in_chans=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tokens = dict()\n",
    "extra_tokens[\"channels\"] = torch.tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]])\n",
    "out = patch_embedding(sample, extra_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collpase_channels(out[0], 'mean').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 13])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.25"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13*0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sample\n",
    "B, Cin, H, W = x.shape\n",
    "# Note: The current number of channels (Cin) can be smaller or equal to in_chans\n",
    "len_keep = int(Cin * 0.4)\n",
    "\n",
    "noise = torch.rand(B, Cin, device=x.device)  # noise in [0, 1]\n",
    "# sort noise for each sample\n",
    "ids_shuffle = torch.argsort(noise, dim=1)  # ascend: small is keep, large is remove\n",
    "ids_restore = torch.argsort(ids_shuffle, dim=1)\n",
    "\n",
    "# keep the first subset\n",
    "ids_keep = ids_shuffle[:, :len_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5,  5,  5,  ...,  5,  5,  5],\n",
       "          [ 5,  5,  5,  ...,  5,  5,  5],\n",
       "          [ 5,  5,  5,  ...,  5,  5,  5],\n",
       "          ...,\n",
       "          [ 5,  5,  5,  ...,  5,  5,  5],\n",
       "          [ 5,  5,  5,  ...,  5,  5,  5],\n",
       "          [ 5,  5,  5,  ...,  5,  5,  5]],\n",
       "\n",
       "         [[ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          ...,\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1]],\n",
       "\n",
       "         [[ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          ...,\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          ...,\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6],\n",
       "          [ 6,  6,  6,  ...,  6,  6,  6]],\n",
       "\n",
       "         [[12, 12, 12,  ..., 12, 12, 12],\n",
       "          [12, 12, 12,  ..., 12, 12, 12],\n",
       "          [12, 12, 12,  ..., 12, 12, 12],\n",
       "          ...,\n",
       "          [12, 12, 12,  ..., 12, 12, 12],\n",
       "          [12, 12, 12,  ..., 12, 12, 12],\n",
       "          [12, 12, 12,  ..., 12, 12, 12]],\n",
       "\n",
       "         [[ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          ...,\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0]]],\n",
       "\n",
       "\n",
       "        [[[ 2,  2,  2,  ...,  2,  2,  2],\n",
       "          [ 2,  2,  2,  ...,  2,  2,  2],\n",
       "          [ 2,  2,  2,  ...,  2,  2,  2],\n",
       "          ...,\n",
       "          [ 2,  2,  2,  ...,  2,  2,  2],\n",
       "          [ 2,  2,  2,  ...,  2,  2,  2],\n",
       "          [ 2,  2,  2,  ...,  2,  2,  2]],\n",
       "\n",
       "         [[11, 11, 11,  ..., 11, 11, 11],\n",
       "          [11, 11, 11,  ..., 11, 11, 11],\n",
       "          [11, 11, 11,  ..., 11, 11, 11],\n",
       "          ...,\n",
       "          [11, 11, 11,  ..., 11, 11, 11],\n",
       "          [11, 11, 11,  ..., 11, 11, 11],\n",
       "          [11, 11, 11,  ..., 11, 11, 11]],\n",
       "\n",
       "         [[ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          ...,\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          ...,\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "          [ 1,  1,  1,  ...,  1,  1,  1]],\n",
       "\n",
       "         [[12, 12, 12,  ..., 12, 12, 12],\n",
       "          [12, 12, 12,  ..., 12, 12, 12],\n",
       "          [12, 12, 12,  ..., 12, 12, 12],\n",
       "          ...,\n",
       "          [12, 12, 12,  ..., 12, 12, 12],\n",
       "          [12, 12, 12,  ..., 12, 12, 12],\n",
       "          [12, 12, 12,  ..., 12, 12, 12]],\n",
       "\n",
       "         [[ 8,  8,  8,  ...,  8,  8,  8],\n",
       "          [ 8,  8,  8,  ...,  8,  8,  8],\n",
       "          [ 8,  8,  8,  ...,  8,  8,  8],\n",
       "          ...,\n",
       "          [ 8,  8,  8,  ...,  8,  8,  8],\n",
       "          [ 8,  8,  8,  ...,  8,  8,  8],\n",
       "          [ 8,  8,  8,  ...,  8,  8,  8]]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_keep.unsqueeze(-1).unsqueeze(-1).repeat(1, 5, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_keep.shape\n",
    "# sample corresponding channels from ce\n",
    "new_ce = torch.gather(ce, 2, ids_keep.unsqueeze(1).repeat(1, ce.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0149,  0.0129,  0.0069, -0.0358,  0.0500],\n",
       "        grad_fn=<SelectBackward0>),\n",
       " tensor(2),\n",
       " tensor([ 0.0149,  0.0129,  0.0069, -0.0358,  0.0500],\n",
       "        grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ce[0, :5, 0], ids_keep[0, 0], ce[0, :5, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ce[0, :5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce[0, :5, 2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather the C dim of the batch of the images in shape B x C x H x W following the index of ids_keep\n",
    "x_keep = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).unsqueeze(-1).repeat(1, 1, *x.shape[-2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 224, 224])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_keep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the binary mask: 0 is keep, 1 is remove\n",
    "mask = torch.ones([B, Cin], device=x.device)\n",
    "mask[:, :len_keep] = 0\n",
    "# unshuffle to get the binary mask\n",
    "mask = torch.gather(mask, dim=1, index=ids_restore)\n",
    "# Per batch channel sampling\n",
    "        # Note this may be slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  1,  6, 12,  0],\n",
       "        [ 2, 11,  1, 12,  8]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = torch.rand((2, 3, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_chans = 13\n",
    "embed_dim = 768\n",
    "patch_size = 16\n",
    "sample = torch.randn(320, 13, 224, 224)\n",
    "proj = nn.Conv2d(\n",
    "    in_chans,\n",
    "    embed_dim*in_chans,\n",
    "    kernel_size=(patch_size, patch_size),\n",
    "    stride=(patch_size, patch_size),\n",
    "    groups=in_chans,\n",
    ")  # CHANGED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj2 = nn.Conv2d(\n",
    "    in_chans,\n",
    "    embed_dim,\n",
    "    kernel_size=(patch_size, patch_size),\n",
    "    stride=(patch_size, patch_size),\n",
    ")  # CHANGED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj3 = nn.Conv3d(\n",
    "    1,\n",
    "    embed_dim,\n",
    "    kernel_size=(1, patch_size, patch_size),\n",
    "    stride=(1, patch_size, patch_size),\n",
    ")  # CHANGED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[[-0.0494, -0.0118,  0.0349,  ..., -0.0208, -0.0393, -0.0144],\n",
       "           [-0.0509, -0.0060,  0.0552,  ...,  0.0210, -0.0201, -0.0489],\n",
       "           [-0.0504,  0.0344,  0.0297,  ..., -0.0276,  0.0257,  0.0005],\n",
       "           ...,\n",
       "           [-0.0518, -0.0534,  0.0306,  ...,  0.0557,  0.0026,  0.0082],\n",
       "           [ 0.0319,  0.0507,  0.0480,  ...,  0.0207,  0.0356, -0.0606],\n",
       "           [-0.0195,  0.0398,  0.0577,  ..., -0.0402, -0.0474, -0.0335]]],\n",
       " \n",
       " \n",
       "         [[[-0.0400, -0.0412,  0.0056,  ...,  0.0204, -0.0555, -0.0264],\n",
       "           [-0.0474,  0.0324, -0.0149,  ...,  0.0083, -0.0221, -0.0540],\n",
       "           [ 0.0518,  0.0413, -0.0549,  ...,  0.0531, -0.0417,  0.0334],\n",
       "           ...,\n",
       "           [-0.0529, -0.0467, -0.0290,  ...,  0.0179,  0.0594, -0.0174],\n",
       "           [ 0.0348,  0.0425, -0.0081,  ...,  0.0413, -0.0467,  0.0195],\n",
       "           [ 0.0395,  0.0289, -0.0382,  ...,  0.0580, -0.0610, -0.0316]]],\n",
       " \n",
       " \n",
       "         [[[-0.0409,  0.0322, -0.0460,  ...,  0.0076,  0.0326, -0.0509],\n",
       "           [-0.0270,  0.0337, -0.0307,  ...,  0.0201,  0.0412, -0.0193],\n",
       "           [-0.0061,  0.0232,  0.0104,  ..., -0.0606,  0.0381,  0.0116],\n",
       "           ...,\n",
       "           [ 0.0306,  0.0276, -0.0329,  ...,  0.0405, -0.0112,  0.0603],\n",
       "           [-0.0392,  0.0204, -0.0008,  ...,  0.0507,  0.0229,  0.0610],\n",
       "           [ 0.0336,  0.0331,  0.0301,  ...,  0.0624, -0.0500, -0.0066]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0614,  0.0228,  0.0293,  ...,  0.0438, -0.0215,  0.0365],\n",
       "           [ 0.0111, -0.0543,  0.0356,  ...,  0.0430, -0.0285, -0.0221],\n",
       "           [-0.0183,  0.0220,  0.0096,  ..., -0.0149,  0.0002, -0.0054],\n",
       "           ...,\n",
       "           [ 0.0031, -0.0406,  0.0298,  ...,  0.0498, -0.0383,  0.0380],\n",
       "           [ 0.0234, -0.0013, -0.0013,  ...,  0.0001, -0.0170, -0.0505],\n",
       "           [ 0.0528, -0.0016,  0.0387,  ..., -0.0159,  0.0043,  0.0544]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0385,  0.0540, -0.0101,  ...,  0.0485,  0.0598, -0.0617],\n",
       "           [-0.0339,  0.0541, -0.0435,  ...,  0.0462,  0.0185, -0.0281],\n",
       "           [ 0.0501, -0.0197, -0.0260,  ..., -0.0571,  0.0442, -0.0532],\n",
       "           ...,\n",
       "           [ 0.0340, -0.0119, -0.0013,  ...,  0.0442,  0.0518,  0.0372],\n",
       "           [-0.0190,  0.0161, -0.0359,  ...,  0.0428,  0.0539, -0.0099],\n",
       "           [-0.0535,  0.0498, -0.0202,  ..., -0.0404, -0.0235, -0.0195]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0590,  0.0285, -0.0031,  ..., -0.0319,  0.0490,  0.0619],\n",
       "           [ 0.0605,  0.0269,  0.0300,  ..., -0.0424, -0.0555,  0.0065],\n",
       "           [ 0.0437,  0.0496, -0.0082,  ..., -0.0056,  0.0397,  0.0065],\n",
       "           ...,\n",
       "           [ 0.0167, -0.0464, -0.0291,  ...,  0.0212,  0.0297, -0.0402],\n",
       "           [-0.0171, -0.0259,  0.0292,  ..., -0.0026,  0.0193,  0.0555],\n",
       "           [ 0.0366, -0.0474, -0.0478,  ...,  0.0007, -0.0228,  0.0325]]]],\n",
       "        device='cuda:1', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0274, -0.0271,  0.0034,  ...,  0.0623, -0.0278, -0.0592],\n",
       "        device='cuda:1', requires_grad=True)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p for p in proj.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2555904, 768]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.numel() for p in proj2.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9216, -2359296)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the number of parameters\n",
    "w1 = sum(p.numel() for p in proj.parameters())\n",
    "w2 = sum(p.numel() for p in proj2.parameters())\n",
    "w3 = sum(p.numel() for p in proj3.parameters())\n",
    "w1-w2, w3-w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, -2359296)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = proj.weight.flatten().shape[0]\n",
    "w2 = proj2.weight.flatten().shape[0]\n",
    "w3 = proj3.weight.flatten().shape[0]\n",
    "w1-w2, w3-w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, -2359296)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1 = proj.bias.flatten().shape[0]\n",
    "b2 = proj2.bias.flatten().shape[0]\n",
    "b3 = proj3.bias.flatten().shape[0]\n",
    "w1-w2, w3-w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj.to('cuda:1')\n",
    "proj2.to('cuda:1')\n",
    "proj3.to('cuda:1')\n",
    "sample = sample.to('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.902925729751587\n",
      "0.1449604034423828\n",
      "1.4818251132965088\n"
     ]
    }
   ],
   "source": [
    "# estimate the timw of the forward pass\n",
    "import time\n",
    "start = time.time()\n",
    "out1 = proj(sample).cpu()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "start = time.time()\n",
    "out2 = proj2(sample).cpu()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "start = time.time()     \n",
    "out3 = proj3(sample.unsqueeze(1)).cpu()\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([320, 3, 224, 224])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[:, torch.tensor([0, 1, 11])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([320, 9984, 14, 14])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([320, 768, 13, 14, 14])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40318025746819064"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5470134688105862"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.uniform(0.25, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
