{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haozhesi/anaconda3/envs/sat/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "\n",
    "from GeospatialFM.data import get_datasets\n",
    "from GeospatialFM.models import *\n",
    "# from utils import load_config\n",
    "from torchgeo.samplers import RandomGeoSampler\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib as mpl\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from GeospatialFM.utils import setup, get_eval_meter, get_data, init_distributed_device\n",
    "from GeospatialFM.data import *\n",
    "from GeospatialFM.models import *\n",
    "from GeospatialFM.loss import *\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.data import ConcatDataset\n",
    "import segmentation_models_pytorch as smp\n",
    "from collections import OrderedDict\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap_model(state_dict):\n",
    "    new_state_dict = OrderedDict()\n",
    "    for key, value in state_dict.items():\n",
    "        new_key = key.replace('module.', '')\n",
    "        new_state_dict[new_key] = value\n",
    "    \n",
    "    return new_state_dict\n",
    "\n",
    "def norm_image(img):\n",
    "    img = img - img.min()\n",
    "    img = img / img.max()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_name = 'mae_cm_reconall_scratch_allTrain'\n",
    "# exp_name = 'mae_unidecoder_scratch_allTrain_norwl'\n",
    "# exp_name = 'sanity_check'\n",
    "n_spectral_blocks = 1\n",
    "n_spatial_spectral_blocks = 2\n",
    "n_spatial_blocks = 9\n",
    "exp_name = f\"mm_mae_fcvit_{n_spectral_blocks}-{n_spatial_spectral_blocks}-{n_spatial_blocks}_bn\"\n",
    "# # exp_name = \"mae_base_cvit\"\n",
    "# device = torch.device('cuda:2')\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(exp_name='mm_mae_fcvit_1-2-9_bn', config_file='GeospatialFM/configs/pretrain_mm_cvit_bn.yaml', opts=None, save_config=False, device='cuda:0', debug=True, finetune=False, distributed=False, world_size=1, rank=0, local_rank=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = {'exp_name': exp_name,\n",
    "        'config_file': 'GeospatialFM/configs/pretrain_mm_cvit_bn.yaml',\n",
    "        'opts': None, \n",
    "        'save_config': False,\n",
    "        'device': 0}\n",
    "args = argparse.Namespace(**args)\n",
    "args.debug = True\n",
    "args.finetune = False\n",
    "device = init_distributed_device(args)\n",
    "cfg, _ = setup(args)\n",
    "cfg.MODEL.MULTI_MODAL.kwargs.spectral_blocks = n_spectral_blocks\n",
    "cfg.MODEL.MULTI_MODAL.kwargs.sptial_spectral_blocks = n_spatial_spectral_blocks\n",
    "cfg.DATASET.task_type = 'multilabel'\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing mm_cvit_base_patch16_224 encoder...\n",
      "Spectral Blocks: 1\tSptial-Spectral Blocks: 2\tSpatial Blocks: 9\n",
      "Number of parameters: 95456256\n"
     ]
    }
   ],
   "source": [
    "save_path = os.path.join(cfg.TRAINER['output_dir'], 'final_model.pth')\n",
    "# save_path = os.path.join(cfg.TRAINER['output_dir'], 'ckpt_epoch10.pth')\n",
    "\n",
    "model = construct_mae(cfg.MODEL)\n",
    "state_dict = unwrap_model(torch.load(save_path, map_location='cpu'))\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model = model.to(device)\n",
    "\n",
    "# print the number of parameters for model\n",
    "num_params = sum(p.numel() for p in model.encoder.parameters())\n",
    "print(f'Number of parameters: {num_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 7087872\n"
     ]
    }
   ],
   "source": [
    "num_params = sum(p.numel() for p in model.encoder.radar_spectral_blocks.parameters())\n",
    "print(f'Number of parameters: {num_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset: BigEarthNet\n",
      "Train Set: 393418\t Val Set: 12586\t Test Set: 125866\n"
     ]
    }
   ],
   "source": [
    "data_idx = 1000 #41982\n",
    "data = get_data(cfg)\n",
    "sample = data['test'].dataloader.dataset[data_idx]\n",
    "for key in sample:\n",
    "    sample[key] = sample[key].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    optical_out = model.forward_recon(sample['image'].to(device), None, slice_patch_tokens=(13, 2), channel_mask_ratio=0., mask_ratio=0.75)\n",
    "    radar_out = model.forward_recon(None, sample['radar'].to(device), slice_patch_tokens=(13, 2), channel_mask_ratio=0., mask_ratio=0.75)\n",
    "    mm_out = model.forward_recon(sample['image'].to(device), sample['radar'].to(device), slice_patch_tokens=(13, 2), channel_mask_ratio=0., mask_ratio=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optical_cls = optical_out['cls_token']\n",
    "radar_cls = radar_out['cls_token']\n",
    "mm_cls = mm_out['cls_token']\n",
    "\n",
    "# calculate the cosine similarity\n",
    "cos_sim = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "optical_radar_sim = cos_sim(optical_cls, radar_cls)\n",
    "optical_mm_sim = cos_sim(optical_cls, mm_cls)\n",
    "radar_mm_sim = cos_sim(radar_cls, mm_cls)\n",
    "\n",
    "print(f'Optical Radar Similarity: {optical_radar_sim.item()}')\n",
    "print(f'Optical MM Similarity: {optical_mm_sim.item()}')\n",
    "print(f'Radar MM Similarity: {radar_mm_sim.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 0\n",
    "rgb_channel = [3, 2, 1]\n",
    "\n",
    "optical_recon = optical_out['recon'].cpu().numpy()\n",
    "radar_recon = radar_out['recon'].cpu().numpy()\n",
    "mm_recon = mm_out['recon'].cpu().numpy()\n",
    "optical_input = sample['image'].cpu().numpy()\n",
    "radar_input = sample['radar'].cpu().numpy()\n",
    "\n",
    "optical_mask = optical_out['mask'].cpu().numpy()\n",
    "radar_mask = radar_out['mask'].cpu().numpy()\n",
    "optical_channel_mask = optical_out.get('optical_channel_mask', None)\n",
    "mm_channel_mask = mm_out.get('optical_channel_mask', None)\n",
    "if optical_channel_mask is not None: \n",
    "    optical_channel_mask = optical_channel_mask.reshape(-1, 256, 13)[0, 0]\n",
    "    optical_channel_mask = optical_channel_mask.cpu().numpy()\n",
    "if mm_channel_mask is not None:\n",
    "    mm_channel_mask = mm_channel_mask.reshape(-1, 256, 13)[0, 0]\n",
    "    mm_channel_mask = mm_channel_mask.cpu().numpy()\n",
    "\n",
    "vis_optical_mask = optical_mask[sample_idx].reshape(14, 14)\n",
    "vis_radar_mask = radar_mask[sample_idx].reshape(14, 14)\n",
    "# scale up the mask from 14x14 to 224x224 in chunks of 16x16\n",
    "vis_optical_mask = np.repeat(np.repeat(vis_optical_mask, 16, axis=0), 16, axis=1)\n",
    "vis_radar_mask = np.repeat(np.repeat(vis_radar_mask, 16, axis=0), 16, axis=1)\n",
    "optical_recon_all = optical_recon[sample_idx].transpose(1, 2, 0)\n",
    "radar_recon_all = radar_recon[sample_idx].transpose(1, 2, 0)\n",
    "mm_recon_all = mm_recon[sample_idx].transpose(1, 2, 0)\n",
    "optical_input = optical_input[sample_idx].transpose(1, 2, 0)\n",
    "radar_input = radar_input[sample_idx].transpose(1, 2, 0)\n",
    "\n",
    "if optical_recon_all.shape[2] >= 13:\n",
    "    vis_optical_recon_o = optical_recon_all[:, :, rgb_channel]\n",
    "    vis_optical_recon_o = norm_image(vis_optical_recon_o)\n",
    "else:\n",
    "    vis_optical_recon_o = None\n",
    "\n",
    "if optical_recon_all.shape[2] > 13:\n",
    "    vis_optical_recon_r = optical_recon_all[:, :, 13]\n",
    "    # vis_optical_recon_r = norm_image(vis_optical_recon_r)\n",
    "elif optical_recon_all.shape[2] == 13:\n",
    "    vis_optical_recon_r = None\n",
    "else:\n",
    "    vis_optical_recon_r = optical_recon_all[:, :, 0]\n",
    "    # vis_optical_recon_r = norm_image(vis_optical_recon_r)\n",
    "\n",
    "if radar_recon_all.shape[2] >= 13:\n",
    "    vis_radar_recon_o = radar_recon_all[:, :, rgb_channel]\n",
    "    vis_radar_recon_o = norm_image(vis_radar_recon_o)\n",
    "else:\n",
    "    vis_radar_recon_o = None\n",
    "\n",
    "if radar_recon_all.shape[2] > 13:\n",
    "    vis_radar_recon_r = radar_recon_all[:, :, 13]\n",
    "    vis_radar_recon_r = norm_image(vis_radar_recon_r)\n",
    "elif radar_recon_all.shape[2] == 13:\n",
    "    vis_radar_recon_r = None\n",
    "else:\n",
    "    vis_radar_recon_r = radar_recon_all[:, :, 0]\n",
    "    # vis_radar_recon_r = norm_image(vis_radar_recon_r)\n",
    "\n",
    "vis_optical_input = optical_input[:, :, rgb_channel]\n",
    "vis_radar_input = radar_input[:, :, 0]\n",
    "vis_optical_input = norm_image(vis_optical_input)\n",
    "# vis_radar_input = norm_image(vis_radar_input)\n",
    "\n",
    "if vis_optical_recon_o is not None:\n",
    "    vis_optical_recon_o = vis_optical_recon_o * vis_optical_mask[:, :, None] + vis_optical_input * (1 - vis_optical_mask[:, :, None])\n",
    "if vis_optical_recon_r is not None:\n",
    "    vis_optical_recon_r = vis_optical_recon_r * vis_optical_mask + vis_radar_input * (1 - vis_optical_mask)\n",
    "if vis_radar_recon_o is not None:\n",
    "    vis_radar_recon_o = vis_radar_recon_o * vis_radar_mask[:, :, None] + vis_optical_input * (1 - vis_radar_mask[:, :, None])\n",
    "if vis_radar_recon_r is not None:\n",
    "    vis_radar_recon_r = vis_radar_recon_r * vis_radar_mask + vis_radar_input * (1 - vis_radar_mask)\n",
    "\n",
    "# # normalize all images\n",
    "# vis_optical_recon_o = norm_image(vis_optical_recon_o) if vis_optical_recon_o is not None else None\n",
    "# vis_optical_input = norm_image(vis_optical_input)\n",
    "# vis_radar_recon_o = norm_image(vis_radar_recon_o) if vis_radar_recon_o is not None else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optical_recon.std(), optical_recon.mean(), radar_recon.std(), radar_recon.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optical_input.std(), optical_input.mean(), radar_input.std(), radar_input.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a graph with 2x3 subplots\n",
    "fig, ax = plt.subplots(3, 4, figsize=(20, 15))\n",
    "# set font size\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "ax[0, 1].imshow(vis_optical_input)\n",
    "ax[0, 1].set_title('Optical Input')\n",
    "ax[0, 2].imshow(vis_radar_input)\n",
    "ax[0, 2].set_title('Radar Input')\n",
    "\n",
    "ax[1, 0].imshow(vis_optical_input)\n",
    "ax[1, 0].set_title('Optical GT')\n",
    "ax[2, 0].imshow(vis_radar_input)\n",
    "ax[2, 0].set_title('Radar GT')\n",
    "\n",
    "ax[1, 3].imshow(vis_optical_mask)\n",
    "# put the title to the right\n",
    "ax[1, 3].set_title('Optical Mask')\n",
    "ax[2, 3].imshow(vis_radar_mask)\n",
    "ax[2, 3].set_title('Radar Mask')\n",
    "\n",
    "if vis_optical_recon_o is not None:\n",
    "    ax[1, 1].imshow(vis_optical_recon_o)\n",
    "if vis_optical_recon_r is not None:\n",
    "    ax[2, 1].imshow(vis_optical_recon_r)\n",
    "\n",
    "if vis_radar_recon_o is not None:\n",
    "    ax[1, 2].imshow(vis_radar_recon_o)\n",
    "if vis_radar_recon_r is not None:\n",
    "    ax[2, 2].imshow(vis_radar_recon_r)\n",
    "\n",
    "# close all the ticks\n",
    "for axi in ax.ravel():\n",
    "    axi.axis('off')\n",
    "\n",
    "fig.suptitle(exp_name, fontsize=32)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['axes.titlesize'] = 32\n",
    "\n",
    "gt_all = np.concatenate([optical_input, radar_input], axis=2)\n",
    "# for gt_all, optical_recon_all, radar_recon_all, pop channel 10\n",
    "gt_all_ = np.delete(gt_all, 10, axis=2)\n",
    "optical_recon_all_ = np.delete(optical_recon_all, 10, axis=2)\n",
    "radar_recon_all_ = np.delete(radar_recon_all, 10, axis=2)\n",
    "mm_recon_all_ = np.delete(mm_recon_all, 10, axis=2)\n",
    "optical_channel_mask_ = np.delete(optical_channel_mask, 10, axis=0) if optical_channel_mask is not None else None\n",
    "mm_channel_mask_ = np.delete(mm_channel_mask, 10, axis=0) if mm_channel_mask is not None else None\n",
    "n_channels = gt_all_.shape[2]\n",
    "# plot every channel optical_recon_all in a 3x5 subplot\n",
    "# plt.rcParams.update({'font.size': 8})\n",
    "# fig, ax = plt.subplots(3, n_channels, figsize=(17, 4))\n",
    "\n",
    "fig = plt.figure(figsize=(56, 16)) \n",
    "gs = GridSpec(4, n_channels+1, figure=fig)\n",
    "\n",
    "for j in range(n_channels):\n",
    "    ax = fig.add_subplot(gs[0, j+1])\n",
    "    ax.imshow(gt_all_[:, :, j])\n",
    "    # ax[0, j].imshow(gt_all_[:, :, j])\n",
    "    if j > 11:\n",
    "        # ax[0, j].set_title(f'RC {j-12}')\n",
    "        ax.set_title(f'RC {j-12}')\n",
    "    elif optical_channel_mask_ is not None and j < len(optical_channel_mask_):\n",
    "        if optical_channel_mask_[j] == 0:\n",
    "            # ax[0, j].set_title(f'OC {j}')\n",
    "            ax.set_title(f'OC {j}')\n",
    "        else:\n",
    "            # ax[0, j].set_title(f'OC {j} (m)')\n",
    "            ax.set_title(f'OC {j} (m)')\n",
    "    else:\n",
    "        # ax[0, j].set_title(f'OC {j}')\n",
    "        ax.set_title(f'OC {j}')\n",
    "    # ax[0, j].axis('off')\n",
    "    ax.axis('off')\n",
    "for j in range(n_channels):\n",
    "    ax = fig.add_subplot(gs[1, j+1])\n",
    "    ax.imshow(optical_recon_all_[:, :, j])\n",
    "    # ax[1, j].imshow(optical_recon_all_[:, :, j])\n",
    "    # ax[1, j].set_title(f'Channel {j}')\n",
    "    # ax[1, j].axis('off')\n",
    "    ax.axis('off')\n",
    "for j in range(n_channels):\n",
    "    ax = fig.add_subplot(gs[2, j+1])\n",
    "    # ax[2, j].imshow(radar_recon_all_[:, :, j])\n",
    "    ax.imshow(radar_recon_all_[:, :, j])\n",
    "    # ax[1, j].set_title(f'Channel {j}')\n",
    "    # ax[2, j].axis('off')\n",
    "    ax.axis('off')\n",
    "for j in range(n_channels):\n",
    "    ax = fig.add_subplot(gs[3, j+1])\n",
    "    # ax[2, j].imshow(radar_recon_all_[:, :, j])\n",
    "    ax.imshow(mm_recon_all_[:, :, j])\n",
    "    # ax[1, j].set_title(f'Channel {j}')\n",
    "    # ax[2, j].axis('off')\n",
    "    ax.axis('off')\n",
    "fig.suptitle(exp_name, fontsize=38)\n",
    "row_labels = ['Ground Truth', 'MSI Recon', 'SAR Recon', 'MM Recon']  # Adjust as needed\n",
    "# Set the x coordinate for the labels, this will need to be adjusted based on your layout\n",
    "x_coord = 1.1\n",
    "\n",
    "# Add the labels to the left of the first column of images\n",
    "for i, label in enumerate(row_labels):\n",
    "    ax = fig.add_subplot(gs[i, 0])\n",
    "    ax.axis('off')  # Turn off the axis if not needed\n",
    "\n",
    "    # Place the text relative to the current axis\n",
    "    ax.text(x_coord, 0.5, label, va='center', ha='right', transform=ax.transAxes, fontsize=32)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(cfg)\n",
    "# samples = next(iter(data['train'].dataloader))\n",
    "# for key in samples:\n",
    "    # samples[key] = samples[key].to(device)\n",
    "\n",
    "# n_batchs = 2\n",
    "# # acumulate 256 samples\n",
    "# samples = {}\n",
    "# for i, batch in enumerate(data['train'].dataloader):\n",
    "#     for key in batch:\n",
    "#         if key not in samples:\n",
    "#             samples[key] = []\n",
    "#         samples[key].append(batch[key].to(device))\n",
    "#     if i == n_batchs:\n",
    "#         break\n",
    "\n",
    "# for key in samples:\n",
    "#     samples[key] = torch.cat(samples[key], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples['radar'].std(), samples['radar'].mean(), samples['image'].std(), samples['image'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "optical_patch = []\n",
    "radar_patch = []\n",
    "mm_patch = []\n",
    "sample_images = []\n",
    "for i, samples in enumerate(tqdm(data['train'].dataloader)):\n",
    "    for key in samples:\n",
    "        samples[key] = samples[key].to(device)\n",
    "    with torch.no_grad():\n",
    "        encode_optical = model.encoder.forward(samples['image'], None, return_dict=True)\n",
    "        encode_radar = model.encoder.forward(None, samples['radar'], return_dict=True)\n",
    "        encode_mm = model.encoder.forward(samples['image'], samples['radar'], return_dict=True)\n",
    "    optical_patch.append(encode_optical['patch_tokens'].cpu().numpy())\n",
    "    radar_patch.append(encode_radar['patch_tokens'].cpu().numpy())\n",
    "    mm_patch.append(encode_mm['patch_tokens'].cpu().numpy())    \n",
    "    sample_images.append(samples['image'].cpu().numpy())\n",
    "    if i >= 4:\n",
    "        break\n",
    "\n",
    "optical_patch = np.concatenate(optical_patch, axis=0)\n",
    "radar_patch = np.concatenate(radar_patch, axis=0)\n",
    "mm_patch = np.concatenate(mm_patch, axis=0)\n",
    "sample_images = np.concatenate(sample_images, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optical_patch = encode_optical['patch_tokens']\n",
    "# radar_patch = encode_radar['patch_tokens']\n",
    "# mm_patch = encode_mm['patch_tokens']\n",
    "optical_patch.shape, radar_patch.shape, mm_patch.shape, sample_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_vis_patch(patch, n_components=3):\n",
    "    # perform PCA on patch\n",
    "    pca = PCA(n_components=n_components)\n",
    "    B, L, D = patch.shape\n",
    "    patch_ = patch.reshape(B*L, D)\n",
    "    try:\n",
    "        patch_ = patch_.cpu().numpy()\n",
    "    except:\n",
    "        pass\n",
    "    pca.fit(patch_)\n",
    "    patch_pca = pca.transform(patch_)\n",
    "\n",
    "    background_mask = patch_pca[:, 0] > 128\n",
    "    foreground_mask = ~background_mask\n",
    "    foregroud_patchs = patch_[foreground_mask]\n",
    "\n",
    "    # do the second PCA on the foreground patchs\n",
    "    pca_fore = PCA(n_components=n_components)\n",
    "    pca_fore.fit(foregroud_patchs)\n",
    "    patch_pca_fore = pca_fore.transform(foregroud_patchs)\n",
    "\n",
    "    processed_patches = np.zeros_like(patch_pca)\n",
    "    processed_patches[foreground_mask] = patch_pca_fore\n",
    "    preprocessed_patches = patch_pca.reshape(B, int(L**0.5), int(L**0.5), 3)\n",
    "    processed_patches = processed_patches.reshape(B, int(L**0.5), int(L**0.5), 3)\n",
    "\n",
    "    # preprocessed_patches = norm_image(preprocessed_patches)\n",
    "    # processed_patches = norm_image(processed_patches)\n",
    "    return preprocessed_patches, processed_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optical_pre_patch, _ = pca_vis_patch(optical_patch)\n",
    "radar_pre_patch, _ = pca_vis_patch(radar_patch)\n",
    "mm_pre_patch, _ = pca_vis_patch(mm_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['axes.titlesize'] = 20\n",
    "\n",
    "fig, ax = plt.subplots(4, 7, figsize=(36, 22))\n",
    "\n",
    "sample_idices = [28, 138, 309, 303]\n",
    "# sample_idices = np.random.choice(len(sample_images), 4, replace=False)\n",
    "print(sample_idices)\n",
    "\n",
    "for i, sample_idx in enumerate(sample_idices):\n",
    "    sample_img = sample_images[sample_idx].transpose(1, 2, 0)[:, :, [3, 2, 1]]\n",
    "    sample_img = norm_image(sample_img)\n",
    "\n",
    "    # pca_img = processed_patches[sample_idx]\n",
    "    pca_img = optical_pre_patch[sample_idx]\n",
    "    # resize the image to 224x224\n",
    "    pca_img = cv2.resize(pca_img, sample_img.shape[:2], interpolation=cv2.INTER_CUBIC)\n",
    "    # pca_img = np.repeat(np.repeat(pca_img, 16, axis=0), 16, axis=1)\n",
    "    pca_img = norm_image(pca_img)\n",
    "\n",
    "    pca_radar = radar_pre_patch[sample_idx]\n",
    "    pca_radar = cv2.resize(pca_radar, sample_img.shape[:2], interpolation=cv2.INTER_CUBIC)\n",
    "    pca_radar = norm_image(pca_radar)\n",
    "\n",
    "    pca_mm = mm_pre_patch[sample_idx]\n",
    "    pca_mm = cv2.resize(pca_mm, sample_img.shape[:2], interpolation=cv2.INTER_CUBIC)\n",
    "    pca_mm = norm_image(pca_mm)\n",
    "\n",
    "    alpha = 0.5\n",
    "    beta = (1.0 - alpha)\n",
    "    gamma = 0\n",
    "    overlaid_img = cv2.addWeighted(sample_img, alpha, pca_img, beta, gamma)\n",
    "    overlaid_radar = cv2.addWeighted(sample_img, alpha, pca_radar, beta, gamma)\n",
    "    overlaid_mm = cv2.addWeighted(sample_img, alpha, pca_mm, beta, gamma)\n",
    "\n",
    "    ax[i, 0].imshow(sample_img)\n",
    "    ax[i, 1].imshow(pca_img)\n",
    "    ax[i, 2].imshow(overlaid_img)\n",
    "    ax[i, 3].imshow(pca_radar)\n",
    "    ax[i, 4].imshow(overlaid_radar)\n",
    "    ax[i, 5].imshow(pca_mm)\n",
    "    ax[i, 6].imshow(overlaid_mm)\n",
    "    \n",
    "\n",
    "    ax[i, 0].set_axis_off()\n",
    "    ax[i, 1].set_axis_off()\n",
    "    ax[i, 2].set_axis_off()\n",
    "    ax[i, 3].set_axis_off()\n",
    "    ax[i, 4].set_axis_off()\n",
    "    ax[i, 5].set_axis_off()\n",
    "    ax[i, 6].set_axis_off()\n",
    "\n",
    "ax[0, 0].set_title('Original Image')\n",
    "ax[0, 1].set_title('Optical PCA Patches')\n",
    "ax[0, 2].set_title('Optical Overlay Image')\n",
    "ax[0, 3].set_title('Radar PCA Patches')\n",
    "ax[0, 4].set_title('Radar Overlay Image')\n",
    "ax[0, 5].set_title('MM PCA Patches')\n",
    "ax[0, 6].set_title('MM Overlay Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
